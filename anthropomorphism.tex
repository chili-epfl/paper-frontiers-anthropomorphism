\documentclass[lettersize, apacite, twoside, HRI]{apa_HRI}
\usepackage{times} % Required package for HRI journal format

% UTF8 support
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{graphicx}
\graphicspath{{figs/}}
\usepackage{tikz}
\usetikzlibrary{shapes}
%
\usepackage{amsmath} 
\usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
\usepackage{color, soul}
\usepackage{url}
\usepackage[numbers, square, comma, sort&compress]{natbib}
\usepackage{multirow}
\usepackage{array}
\usepackage{fixltx2e}
\usepackage{textcomp}

\usepackage[draft]{fixme}
\rightheader{Journal of Human-Robot Interaction}
\leftheader{Fink et al.}

\newcommand{\eg}{{\textit{e.g.~}}}
\newcommand{\etal}{{\textit{et al.~}}}
\newcommand{\ie}{{\textit{i.e.~}}}

\hyphenation{com-mon-ly}


\title{On the Dynamics of Anthropomorphism in Robotics
}

\author{Julia Fink, Séverin Lemaignan, Pierre Dillenbourg}
\affiliation{ Computer-Human Interaction in Learning and Instruction (CHILI) \\
              Ecole Polytechnique Fédérale de Lausanne (EPFL) \\
              CH-1015 Lausanne, Switzerland
}
\abstract{While anthropomorphism in robotics is a commonly discussed trait of human-robot interaction (HRI), it is paradoxically an overlooked research topic. This article attempts first at providing a comprehensive synthesis of the social phenomenon of \textit{attributing human characteristics to robots}. It draws on social sciences and psychology, as well as on a critical survey of existing literature in the HRI community, to ground the concept of \textit{anthropomorphism}. We further present different kinds of \textit{anthropomorphic design} of robots and outline their role in social robotics. We then propose to go beyond the traditional perception of anthropomorphism as a static feature. We suggest to understand anthropomorphism as a dynamic, context-dependent process. This also provides an account of the so-called \textit{novelty effect}. To this end, we introduce an initial function of anthropomorphism that models the phenomenon along three interaction phases. Our function is supported by results of a long-term study that we conducted in a real human environment.}



\keywords{Anthropomorphism, Design, Human-Robot Interaction, Social Issues in Robotics, Acceptance of Robots}

\begin{document}
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				INTRODUCTION
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Anthropomorphic Design and Anthropomorphism}
\label{sec:intro}

	 Since the very beginning of robotics, there has been a trend of making robots human-like. Personal robots are designed with more or less human-like shapes or characteristics, and are able to use and react to human social behavior, such as facial expressions or nonverbal gestures. We call this design approach \textbf{anthropomorphic design}, which hereafter refers to human-like \hl{(life-like?)} characteristics in a robot (realized in its shape, behavior, interaction, etc.). Even though this design principle is not exclusive for robots, the topic has received remarkable attention in the domain of (social) robotics. On one hand, human-like design of robots seems to be beneficial from a technical viewpoint: for finding efficient solutions in the technical and mechanical development of a robot (e.g. bio-inspired robots) in order to optimally fit the robot into our to humans adapted physical space. On the other hand, human-like characteristics in a robot also concern the social space, the acceptance of a robot, as well as how people perceive it, form expectations toward it, and in turn treat it. A robot that looks and acts like a human raises different expectations than a functionally designed robot \hl{[REF]}. The anthropomorphic design of robots is thus a crucial aspect for the study of acceptance of robots in daily life and in the domain of social robotics in general. 
	
     Why does anthropomorphic design seem to be so popular in HRI? Amongst others, a human-like shape and human-social characteristics of a robot aim to enable effective and natural interaction between humans and robots. As robots are generally something unfamiliar and new to humans, the underlying argumentation is that when a robot has a human-like shape and displays human social cues, it is easier for people to interact with it. A robot's anthropomorphic design suggests to the human user to understand and treat it to some extend similar to a human, thus in a social manner. This behavior has been extensively studied in HCI and is explained by the \emph{Media Equation Theory}, which states that people's interactions with computers, television, and new media are fundamentally social and natural, just like interactions in real life \cite{reeves_media_1996}. Since robots are physically embodied agents, it is consequently very likely that people respond socially to them. The anthropomorphic design in a robot further encourages a person to ascribe / attribute human characteristics to it (e.g. intention, emotions, personality). To this end, anthropomorphic design of robots aims to make the system understandable, thus predictable, and acceptable. The conclusion builds on the assumption that humans prefer to interact with machines (and robots) in the same way they interact with humans \cite{fong_survey_2003} because they are familiar to these kind of interactions. \hl{The implicit social mechanism which is exploited, is called \textbf{anthropomorphism}}\fxfatal{Discuss also \emph{anthropomorphic effects} as the observable part of anthropomorphism}. It describes the phenomenon of a person ascribing human-like characteristics (e.g. beliefs, intentions, personality) to a non-human artifact, such as a robot. Anthropomorphism also concerns a person's reasoning about a non-human agent as if that agent were human-like (\textit{i.e.} a cognitive process without the action of making a verbal statement with attribution, for instance). In robotics, this social phenomenon is enhanced by using anthropomorphic forms in the design of robots, thus these two aspects are closely related to each other. 
	
	As in the near future it is likely that a growing number of social robots will be deployed in everyday environments, the analysis and understanding of anthropomorphism and related social dynamics in HRI becomes increasingly important.
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				ANTAGONISM
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{The Antagonism of Anthropomorphic Design}
\label{sec:2}

	
	In the first place, robotics seems to benefit from anthropomorphic design and people's tendency to anthropomorphize robots. However, there is the other side: a not yet very well defined thin line separates acceptable human-like forms in robots from creepy artificial \textit{almost} human-like appearing robots. The underlying theory for this viewpoint is stated as the \textit{Uncanny Valley} \cite{mori_uncanny_1970} which suggests that artificial human-like forms are only acceptable up to a certain degree but lead to reluctance if they fail in trying to attain human-likeness \hl{cross-ref to later and figure}. The usage of different kinds of anthropomorphic forms in robots is still controversially discussed. Some developers and researchers clearly oppose human-like forms in robots but rather suggest animal-like shapes or caricature-like appearance. Another sensitive aspect is that with robots to closely resemble a human, also ethical issues arise. For instance, we need to consider how far we actually want an \textit{artificial agent} to resemble ourselves and how far it should act `artificially socially' toward humans, and what happens as soon as it is considered a \textit{moral agent} \cite{sullins_when_2006}. Using \textit{socially interactive robots} in contexts involving elderly care or rehabilitation for disabled / handicapped persons, autistic children is also a controversially discussed topic \cite{robins_robots_2005}.
	
	Literature on anthropomorphism (in robotics) is quite diverse and one strives hard to extract a coherent conclusion. There is no commonly accepted definition about the terms used and the terminology is not clear. However the terms \textit{anthropomorphic or human-like are often used as if their meanings are clear and agreed upon"} \cite{persson_anthropomorphism_2000}. Consequently, Duffy \cite{duffy_anthropomorphism_2002} argues that terms might even be misused. For instance, some researchers refer to \textit{"the robot's level of anthropomorphism"} \cite{bartneck_is_2007}, however, others argue that anthropomorphism emerges in the \textit{interaction} between the technology and the user, thus a system or an artifact does not "contain anthropomorphism" \textit{per se} \cite{persson_anthropomorphism_2000} but only gives rise to the process of anthropomorphizing in a given user and situation. Further, robotics is a multi-disciplinary field and researchers from very different domains might have diverse or even contradictory understandings of anthropomorphism. Epley \textit{et al.} \cite{epley_seeing_2007} notice that despite the fact that anthropomorphism in the perception of non-human agents is commonly observed, it is poorly understood. The phenomenon itself has been found to be very complex but sometimes subtle and hard to study. Another constraint that limits the reliability of some findings is, that most experiments on anthropomorphism are conducted in controlled lab-settings during short-term interactions. This experimental setting (short term and laboratory context) can be critical when studying a social phenomenon like anthropomorphism and possibly lead to over-interpretations. Some studies also seem to contrast two or more different anthropomorphic and mechanical systems that might not be appropriate for comparison under the given context and research question. \hl{say more}
	
	To sum it up, while anthropomorphism in robotics is a commonly discussed and studied trait of human-robot interaction (HRI), we think it is paradoxically an overlooked research topic. The understanding of anthropomorphism in robotics seems to not take into account the wide range of phenomena that it encompasses. The traditional understanding of anthropomorphism in robotics to date, considers two main factors that account for the social phenomenon: the characteristics of \textbf{1) the robot's design} (degree of human-likeness) and the psychological determinants in \textbf{2) the human user} (see \cite{epley_seeing_2007}). It has been shown that both these factors can facilitate or hinder anthropomorphism. We propose to go beyond this traditional perception of anthropomorphism as a static feature of HRI. Based on Persson \textit{et al.}'s \cite{persson_anthropomorphism_2000} argumentation that anthropomorphism is a multi-layered phenomenon which arises in different levels, we suggest to understand anthropomorphism as a dynamic, context-dependent process. To this end, we apply Persson \textit{et al.}'s six levels on anthropomorphism to HRI and introduce three interaction phases. These interaction phases of anthropomorphism reflect also the results of a long-term study that we conducted in a real human environment and provide an account of the so-called \textit{novelty effect}. Consequently, we would like to draw attention to two \textit{dynamics in anthropomorphism}, namely, the context of use, and the fact of getting used to a system over time. We propose to add these two aspects as a third factor, the characteristics of \textbf{3) the interaction} (time and space), to the existing two accounts of anthropomorphism (robot and user). 
					
	We would further like to review and discuss research on anthropomorphism in robotics and human-like design of robots. We first provide a comprehensive understanding of the phenomenon drawing on theories from developmental psychology and cognitive sciences. We then present the trends of different kinds of anthropomorphic forms in robots and discuss their role in social robotics. The article integrates related work from human-robot interaction studies, reporting on findings from experiments with human subjects interacting with and evaluating various types of systems. We try to give a coherent view on the topic, outline similarities and antithetic findings, and contribute to a better understanding of anthropomorphism in robotics, and the acceptance of human-like characteristics in robots. We also aim to constructively discuss anthropomorphic design of personal and socially interactive robots. 
	

	 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				ANTHROPOMORPHISM: EXPLANATIONS & BACKGROUND
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Anthropomorphism as a Social Phenomenon}
\label{sec:3}

	The term \textbf{anthropomorphism} is used in different senses throughout natural sciences, psychology, Human-Computer Interaction, and Human-Robot Interaction \cite{duffy_anthropomorphism_2003}. There is no single accepted definition. Originally, anthropomorphism comes from the Greek \textit{`anthropos'} for `man' (or `human') and \textit{`morphe'} for `form/structure' (or `shape'). It can be understood as people's tendency to think of objects as if they had human characteristics, and consequently, attribute / ascribe specific human characteristics to these non-human entities and artifacts (including animals, and robots) \cite{duffy_anthropomorphism_2003,schmitz_concepts_2011}. Apart from anthropomorphism there is also \textbf{animism}, the \textit{"attribution of life to the nonliving"} \hl{in Schmitz 2011, cite Piaget original text!}. Often synonymously used to animism is \textbf{zoomorphism}, which describes the case when non-lifelike objects are associated with animalistic attributes, excluding human-specific traits. Both anthropomorphism and zoomorphism can be embraced by the concept of \textbf{life-likeness}. \footnote{The inverse process, dehumanization \cite{haslam_dehumanization:_2006}, or mechanomorphism \cite{caporael_anthropomorphism_1986} also exists.}
		
	Commonly, anthropomorphism can also be understood as \textbf{humanization} or \textbf{personification} of anything other than a human being. The phenomenon of personifying something has ancient roots, \textit{e.g.} in mythology but also in storytelling. Already in prehistoric artworks and illustrations zoomorphic (animal-shaped) or anthropomorphic shapes were used to represent natural forces or great spirits, for instance. A more recent example is Milo Winter's illustration from 1919, \textit{"The North Wind and the Sun"} (Figure \ref{fig:1}), in which both north wind and sun are given a human face (anthropomorphized). Similarly, when parents explain their children about nature, they tend to use anthropomorphisms, \textit{e.g.} saying the skies would cry when it rains. More generally, a possible explanation for why people anthropomorphize is that by doing so, the subject is made graspable, understandable, somehow predictable, and one could feel more empathetic toward it. For instance, people commonly anthropomorphize their pets, ascribing mental states, intentions or feelings to them \cite{eddy_attribution_1993}. Interestingly, pet-ownership seems to have a significant impact on human-robot interaction: several studies suggest that pet-owners are more likely to anthropomorphize technologies and robots than non pet-owners \hl{references!}.

 \begin{figure}
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[scale=0.91]{north-wind.jpg}
  \includegraphics[scale=0.91]{sun.jpg}
% figure caption is below the figure
 \caption{Milo Winter illustration of Aesop Fable \textit{The North Wind and the Sun}, 1919; both natural forces wind and sun are anthropomorphized with a human face; picture source: wikipedia}
 \label{fig:1}       % Give a unique label
 \end{figure}
 

\subsection{Explanations for Anthropomorphism}
\label{sec:3.1}

	According to Lee \textit{et al.} \cite{lee_human_2005}, there are two main perspectives in explaining people's tendency to anthropomorphize. The first one explains anthropomorphism from the design of the artifact (anthropomorphic form in the design). It assumes that humans directly respond to life-like or social cues that an object or system emits, without thoughtful mental processing, by simply applying stereotypes and heuristics to it. In fact, from early childhood on, humans are inherently well-trained to perceive life \cite{epley_seeing_2007}. Schmitz \cite{schmitz_concepts_2011} describes that within the visual scope of design, the outer appearance can have an important impact on the overall perception of an object. The basic assumption here is that if an artifact appears much like a human it is likely to be treated similar to a human. If this explanation of anthropomorphism is correct, people may respond automatically to social cues emitted by a robot, and apply human-human social schemas and norms to these interactions.
	
	The second perspective applies a human-centered, cognitive viewpoint where anthropomorphism is described through people's specific mental model they construct about how an artifact works the way it does. According to v. Foerster \hl{ref} \textit{"we anthropomorphize because it allows us to explain things we do not understand in terms that we do understand, and what we understand best is ourselves as human beings"} \cite{hegel_understanding_2008}. This is consistent with the \hl{familiarity thesis (18)} \cite{hegel_understanding_2008} which claims we understand the world based upon a mental model of the world that we are most familiar with. Consequently, people tend to thoughtfully develop a mental model of agents in their environment and make inferences about it based on what is familiar to them. This point of view implicitly builds on a person's ability to attribute mental states to oneself and others, which is called \textit{Theory of Mind}. A theory of  mind for other agents enables us to attribute intentionality to those agents \cite{leslie_pretense_1987,admoni_multi-category_2012}. If a system behaves much like a human being (e.g. emits a human voice), people's mental model of the system's behavior may approach their mental model of humans, though the model may differ in some important aspects \hl{ref? Schmitz?}. In turn, people's estimation of a robot's `knowledge' and its capabilities / abilities affects the way they relate to it. Research examined the validity of the mental model concept with various kinds of robots \cite{schmitz_concepts_2011,kiesler_mental_2002}. Findings suggest that people tend to hold richer mental models about anthropomorphic robots in contrast to mechanic ones \cite{kiesler_mental_2002}.
  
\hl{here or later? : familiarity thesis does probably not hold after one get's acquantained with a robot.}

\subsection{Insights from Social and Developmental Psychology}
\label{sec:3.2}

	To understand the social phenomenon of anthropomorphism better, it makes sense to take a look at studies and explanations from (developmental) psychology. The phenomenon of attributing intentions and \hl{animacy} to simple shapes based on motion has been intensively studied in (developmental) psychology. Two famous studies on the perception of and attribution to simple things have been done in the mid 1940s: Heider and Simmel's work on the \textit{attribution theory} \cite{heider_experimental_1944} and Michotte's studies on \textit{the perception of causality} \cite{michotte_perception_1963}. In both experiments, participants viewed animations of simple shapes, such as circles or triangles (see Figure \ref{fig:animacy_attribution}). Asked to describe what they observed, interestingly, most people developed elaborate stories, attributing motivations, emotions and relationships between the objects.

\begin{figure}\centering
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[scale=0.6]{heider-simmel_animation.jpeg}
% figure caption is below the figure
 \caption{Fritz Heider and Mary-Ann Simmel's animated film to study people's tendency to attribute animacy and intention to simple shapes; \textit{An experimental study of apparent behaviour}, 1944}
 \label{fig:animacy_attribution}       % Give a unique label
 \end{figure}

	What is a person's motivation to attribute human characteristics to simple geometric shapes, or more sophisticated, anthropomorphic shapes, animated or not? Irrespective of the artifact's characteristics, there are psychological theories to explain the phenomenon. An interesting recent psychological theory of anthropomorphism (also related to robotics) is provided by Epley, Waytz, and Cacioppo \cite{epley_seeing_2007}. The authors established a three-factor theory of when people are likely to anthropomorphize based on psychological determinants. Namely, the theory suggests that some people are more likely to anthropomorphize when:

\begin{itemize}
	\item anthropocentric knowledge is accessible and applicable to the artifact (\textit{elicited agent knowledge}),
	\item they are motivated to explain and understand the behavior of other agents (\textit{effectance motivation}), and
	\item they have the desire for social contact and affiliation (\textit{social motivation}).
\end{itemize}

	Epley \textit{et al.} describe that \textit{elicited agent knowledge} is a \textbf{cognitive determinant  of anthropomorphism} which is understood as the activation of knowledge about humans (or the self) when making inferences about non-human agents. One basic reasons for this are a person's physical constraints of being a human and nothing else. Consequently, one has no other experience than the self and in turn people tend to make inferences about others' mental states by relying inordinately on their own mental states. \footnote{Using one's own mental states and characteristics as a guide when reasoning about other humans is ego-centrism; when reasoning about non-human agents is anthropomorphism. See Epley, 2007 \textit{et al.} \cite{epley_seeing_2007}} Also empirical findings suggest that knowledge about humans in general, or self-knowledge in particular, is likely to serve as a readily accessible base for induction when reasoning about non-human agents. This tendency is usually stronger in young children and decreases with cognitive development and the learning to distinguish the self from other humans, and non-human agents. 
	
	Both \textit{effectance} and \textit{sociality} are \textbf{motivational determinants of anthropomorphism}. \textit{Effectance} is understood as the motivation to interact effectively in one's environment: understand, predict, \hl{reduce uncertainty (this feeds again our hypothesis that as soon as a robot is not uncertain anymore, there is no need to keep on anthropomorphizing it)} about one's environment and the agents that inhabit it. According to Epley \textit{et al.}, anthropomorphism serves as one way to reduce uncertainty and increase comprehension of events in one's environment. They mention for instance, children (as they are in their early stages of life) appear to be more likely to anthropomorphize than adults, as they might feel more uncertain within their environment.
	\textit{Sociality} describes the motivation for social contact, social connection, and social approval from other agents. Importantly for anthropomorphism, this social connection appears to be satisfied by connections with \hl{ \textit{"two of the most commonly anthropomorphized hon-human agents, namely pets and religious agents"}} \cite{epley_seeing_2007}. According to Epley \textit{et al.}, the motivation of being socially connected increases the tendency to anthropomorphize non-human agents because first sociality motivation increases the tendency to perceive human-like characteristics and traits even in non-human agents, and second it increases the tendency to search for sources of social connection in one's environment. Consequently, the authors suggest \textit{"[...] those who are chronically lonely should be more likely to anthropomorphize nonhuman agents than those who are more chronically connected"}. 
	
	\hl{BRIDGE}
	


\subsection{Anthropomorphism in Robotics}
\label{sec:3.3}
	
	Anthropomorphism is a commonly observed phenomenon in human-robot interaction. Studies showed that there are people who directly talk to their robot (even if it does not recognize speech), give it a name, greet it, wonder about its intentions or actions \cite{eyssel_anthropomorphic_2010,fink_anthropomorphic_2012,forlizzi_how_2007,fussell_how_2008,kiesler_anthropomorphic_2008}. It has frequently been described that people ascribe intentions or emotions to their domestic robot, such as to a Roomba vacuum-cleaning robot \cite{krumm_my_2007,sung_robots_2009} or their AIBO robotic dog \cite{friedman_hardware_2003}. However, people's tendency to anthropomorphize technologies has not only been observed with robots but described earlier in human-computer interaction and related to digital agents \cite{reeves_media_1996, nass_anthropocentrism_1995}. Though, the phenomenon seems to be more coined in human-robot interaction than in other human-machine interaction fields. What makes anthropomorphism special in robotics, is probably related to the (unique) characteristics of robots in contrast to other technologies. Robots are embodied, physical agents, autonomously acting right next to us, and able to respond intelligently to us and the environment. These are factors that seem to facilitate anthropomorphism, due to the nature of the phenomenon and its origins itself. In robotics, anthropomorphism is further encouraged through specific anthropomorphic design of a robot. But what is the interest, which underlies the efforts of enhancing anthropomorphism through specific anthropomorphic design in robots? Why does anthropomorphism seem to be so important in robotics? There is no one single answer to this question but certainly, developers and designers have discovered that anthropomorphism seems to be beneficial for human-robot relations, especially with socially interactive robots \cite{fong_survey_2003}. More concretely, it has been found that the appearance and function of a \hl{product (research in marketing?)}) impacts how people perceive it, interact with it, and build long-term relations with it \cite{bartneck_shaping_2004}. Consequently, the domain of (social) robotics tries to exploit this fact by enhancing anthropomorphism through anthropomorphic robots: \textit{"Applying anthropomorphism or zoomorphism changes the way how users try to understand and make sense of a [system] by projecting everyday \hl{expectations} of human and animalistic life onto it."} \cite{schmitz_concepts_2011}. Studies have further shown that perceived similarity between the user and the robot influences the intense of the participants' attributions towards the robot. Thus, anthropomorphism plays an important role in the design of robots as it is strongly related to the perception of intelligence, fun, the attribution of intentions and thus the predictability of the robot \hl{which ref??}.
	
	
	
%	Duffy defines anthropomorphism as "the tendency to attribute human characteristics to inanimate objects, animals and others with a view to helping rationalise their actions." \cite{duffy_anthropomorphism_2003}. This definition directly tries to give an explanation for why people tend to anthropomorphize robots, namely, in order to rationalize their actions, which seems to be effective as long as the robot is not very familiar to the human interaction partner. \hl{familiarity aspect LATER} Attributing familiar human-like qualities to a robot can serve to make the robot more familiar, explainable, or predictable \cite{epley_seeing_2007}. Further Duffy argues that anthropomorphism includes "attributing cognitive or emotional states to something based on observation." \cite{duffy_anthropomorphism_2003} \hl{BRIDGE, explain better} This is important for the acceptance of socially interactive robots \cite{fong_survey_2003} in daily life environments. As robots have to deal with people's acceptance to become useful devices and collaboration partners for humans, anthropomorphic robot design is amongst other reasons used to make people anthropomorphize (or socialize) the robot, treat it socially, act empathetical toward it. 

	


	

	"[...] the experiment demonstrates that human beings implicitly attribute human-like qualities, such as mental states, to nonhuman agents. This finding was evident on a neurophysiological level as well as behavioral level." \cite{hegel_understanding_2008}
	


\subsection{Anthropomorphism as a multi-layered phenomenon}
\label{sec:3.4}

Anthropomorphism can also be viewed as an \textit{experience} that arises in the \textit{interaction} between a set of user expectations and external reality \cite{persson_anthropomorphism_2000}, (see Figure)

an \textit{understanding} of complex -- not necessarily human -- patterns of behavior in the world, in order to make sense of it: \textit{"Anthropomorphism is a way of simplifying and thereby making sense of the environment by projecting a host of expectations about human life onto aspects of that environment."} \cite{persson_anthropomorphism_2000}
Persson \textit{et al.} explored anthropomorphism triggered by computer interfaces and system and we believe their perspective on anthropomorphism could also be applied in HRI. The authors suggest that the social phenomenon is not only one single process but that it involves several levels, \textit{e.g.} primitive psychology, folk-psychology, social stereotypes, and emotional anthropomorphism. We would like to take up the proposition to discriminate different levels of anthropomorphism, since each has its own characteristics and involves specific types of user expectations. This differentiation could allow to draw inferences on the human-robot relationship from the observed level of anthropomorphism.


\begin{figure}\centering
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[scale=0.42]{persson_anthropomorphism.png}
% figure caption is below the figure
 \caption{Anthropomorphism emerges in the (real or imagined) interaction between robot and user; illustration taken from \cite{persson_anthropomorphism_2000} \hl{maybe we don't put the figure here, it was just to illustrate what I mean}}
 \label{fig:anthropomorphism_and_interaction}       % Give a unique label
 \end{figure}
	


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				HUMAN-LIKE DESIGN IN ROBOTS
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Human-like Design in Robots}
\label{sec:4}

	Anthropomorphic design means an imitation of human form (or natural form, in a broader understanding) \cite{disalvo_seduction_2003}. Concepts of anthropomorphic or other life-like forms can be found in a variety of interactive objects and effects of this design approach are studied in disciplines such as affective computing, tangible interaction or industrial design. In a robot, anthropomorphic design can be realized in \textit{1)} a robot's physical (visible) form / shape (embodiment / appearance), \textit{2)} its behavior (e.g. motion), and \textit{3)} the kind of interaction / communication (e.g. modality) that it enables or triggers. Especially socially interactive robots often make use of `human social' behavior cues, such as express / perceive emotions, communicate with high-level dialogue, learn / recognize models of other agents, establish / maintain social relationships, use natural cues (gaze, gestures, etc.), exhibit distinctive personality and character, or learn / develop social competencies \cite{fong_survey_2003}.
 

\subsection{Human-like embodiment (form / shape)}
\label{sec:4.1}

	The degree of human-like shape in a robot, also its morphological similarity, is the extent to which a non-human agent's observable features look human-like. \cite{epley_seeing_2007} Fong \textit{et al.} classify four categories of a robot's aesthetic form: \cite{fong_survey_2003}
	
\begin{itemize}
	\item anthropomorphic: structurally and functionally similar to a human
	\item zoomorphic: imitation of forms of living creatures, e.g. animal or pet design
	\item caricatured: using a character or caricature form, e.g. inspired from animation
	\item functional: reflecting the task a robot should perform
\end{itemize}

	For some robots, it seems to be difficult to assign them to only one of these categories. How to categorize, for instance, a mainly functional robot which has only a human-like head? It is also interesting that each of the four categories follows specific design principles to fulfill different goals. For instance, zoomorphic robots seem to help creating a "companionship" relation (e.g. similar to the owner-pet relation), whereas the anthropomorphic design seems to foster rather a human-social relation between the robot and the human and also tries to give the impression of the robot being a more sophisticated interaction partner \cite{disalvo_all_2002,fong_survey_2003,kiesler_mental_2002}. Accordingly, a robot's functionality should be reflected in it's design because it strongly impacts what kind of expectations people have of the robot \hl{ref, matching hypothesis}: \textit{"The device's visual appearance will often shape first impressions and can therefore play a considerable role in establishing first expectations."} \cite{schmitz_concepts_2011} What however is the best design for a multi-purpose robot that not only vacuums floors but also aims to interact socially with the user? This seems to be a fundamental question in HRI and the design of robots. Interestingly, it has been observed that body parts of a robot that are associated with senses could indicate that the robot is capable of perceiving the corresponding modality (e.g. eyes suggest seeing and ears hearing, respectively. \cite{schmitz_concepts_2011} Schmitz calls this notion \textbf{anthropomorphic affordances}, which describe affordances of an artifact that are impacted by its anthropomorphic shape and suggest to a user a  specific action or interaction. Consequently, if a more human-like shaped robot leads to higher expectations from the user side, it seems to be exeptionally difficult at this moment, to build a satisfying anthropomorphic robot. Moreover, there are also practical affordances that a robot's shape brings along. A legged robot is supposed to be able to walk and climb stairs whereas a wheeled one would probably not be able to do so. \hl{Sullivan: form follows funtion!}
	
\subsection{Human-like behavior}
\label{sec:4.2}

	Besides anthropomorphic shape, also a robot's behavior, e.g. the particular way of how it moves, can be human-inspired (which is in fact often defined by its morphology). According to Epley \textit{et al.} \textit{"at least two dimensions of similarity seem particularly important for anthropomorphism to occur -- similarity in motion and similarity in morphology"} \cite{epley_seeing_2007}. Similarity in motion might not only be walking on two feet but also the speed of movements of a robot, which when adapted to a human, have a positive effect on the usability and perception of the robot from the user cite \hl{ref!!}. The aspect is less important for robots in automation (e.g. assembly lines, production) which usually do not directly interact with humans.
	
	Another aspect of human-like behavior in robots is autonomy and pro-activity. Schmitz argues that both can be a fundamental strategy in order to evoke anthropomorphic / zoomorphic interpretation \cite{schmitz_concepts_2011} \hl{ref 33}. \hl{more on autonomy and pro-activity, transparency}

	"On a next level, \textbf{stereotypical behavior}, which expresses e.g. shyness of curiosity, addresses more complex processes but adds essentially to anthropomorphic strategies [38] [46]." \cite{schmitz_concepts_2011}
	
	\hl{Severin: mention the need to be "complete enough not to be predictable" --> toys that are predictable are quickly boring and humans are really good at identifying simple logical behaviors. / Julia: role of uselessness in robots, surprise factor}


\subsection{Human-like interaction / communication}
\label{sec:4.3}


	"The mere \textbf{presence of voice} is another strong trigger for anthropomorphic perception \hl{(33)}, irrespective of contents and sounds." \cite{schmitz_concepts_2011}

	"Besides speech, the acoustic channel can be used to deliver alternative feedback that resembles \textbf{life-like, physiological sounds or haptics} instead of conventional feedback, for example pulse, breath, snore or cough [...]." \cite{schmitz_concepts_2011}


Others: proxemics


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				DOES ANTHROPOMORPHISM MAKE ROBOTS MORE SOCIAL?
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Does anthropomorphism make robots more social?}
\label{sec:5}

	In general, it is suggested that increasing human-likeness of a robot	 will lead to more perceived \textit{affinity} from the human side \cite{mori_uncanny_1970}. This theoretical concept is also supported by psychological determinants of perceiving human-likeness in something non-human: \textit{"the more similar in appearance, the more people are likely to use themselves as a source of induction and anthropomorphize these nonhuman agents"} \cite{epley_seeing_2007}. Further, empirical studies have shown that robots with human-like forms can enhance social responses from humans which in turn can have a positive impact on acceptance \cite{venkatesh_theoretical_2000,duffy_anthropomorphism_2003,goetz_cooperation_2002}.  People responded more positively to an artifact that displayed human-like behavioral characteristics (emotions, facial expression) in contrast to a purely functional design \cite{eyssel_anthropomorphic_2010,krach_can_2008,reeves_media_1996,riek_how_2009}. Overall, these results suggest that human-like features in robots enhance anthropomorphism, and in turn create a social view toward the robot.


	"The anthropomorphic design of human-machine interfaces is inevitable. The important criterion is to seek a balance between people's expectations and the machines capabilities." \cite{duffy_anthropomorphism_2002}

	"What is the ideal set of human features that could supplement and augment a robots  social functionality?" \cite{duffy_anthropomorphism_2002}


	Though, the 'anthropomorphic design principle" seems beneficial, it also raises ethical issues and has been reviewed critically in terms of acceptance. How far do we want a robot to resemble a human or act like a human?

	Findings that support anthropomorphic form in robots because they found people respond with anthropomorphizing these kind of robots, and in turn act more social toward them or accept them more easily:

	\hl{empathy --> check Iolanda's paper}

\subsection{Socially interactive robots}
\label{sec:5.1}

Evaluation and classification of social robots


\subsection{Too much human-likeness?}
\label{sec:5.2}

\begin{figure}\centering
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[scale=0.6]{uncanny-valley.jpg}
% figure caption is below the figure
 \caption{Mashiro Mori, illustration of the \textit{Uncanny Valley}, originally from 1970; picture from a manuscript version of \cite{mori_uncanny_2012}}
 \label{fig:uncanny_valley}       % Give a unique label
 \end{figure}




	The \textit{Uncanny Valley} hypothesis \cite{mori_uncanny_1970} models people's reactions to technologies that resemble a human too close while still not being one (see Figure). The theory hypothesizes that a person's response to a human-like robot would abruptly shift from empathy to revulsion as it approached, but failed to attain, a lifelike appearance \cite{mori_uncanny_1970}. Starting with low degrees of anthropomorphic cues in a robot, humans seem to readily accept and prefer them compared to purely mechanical robots. In general, one can say that up to a certain (yet not very well defined) degree, the more human-like the robot, the more affection it can engender through familiar communication references.
	
	when slowly increasing its human-likeness, the more affection 
	
The idea of the hypothesis follows Freud's description of the uncanny (a translation from the German word `unheimlich') \hl{ref Freud, The Uncanny}: "it derives its terror not from something externally alien or unknown but - on the contrary - from something strangely familiar which defeats our efforts to separate ourselves from it". \cite{hegel_understanding_2008}

	Also: Simulation Theory

	Findings that oppose anthropomorphic design in robots as people respond negatively to it:
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				SKEPTICAL REVIEW OF ANTHROPOMORPHISM IN HRI
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Does anthropomorphism make robots more social?}
\label{sec:6}

We believe that the prevalent mostly observed anthropomorphic stances in short-term experiments do not fully embrace this complex social phenomenon. For instance, when reading through literature on anthropomorphism in robotics one can get the impression that it is taken as a given fact that once people attribute human characteristics to a robot, they will always keep on doing so.
	
	short term
	
	lab context
	
	fake comparison of different robots that are not appropriate for comparison	
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				OUR MODEL
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{A Model of the Dynamics of Anthropomorphism}
\label{sec:dynamics_model}


\begin{figure*}[htb]
\centering


\begin{tikzpicture}

% background shading
\path[fill=gray!20] (0,0) rectangle (0.6,5.5);
\path[fill=gray!50] (0.6,0) rectangle (5.2,5.5);
\path[fill=gray!20] (5.2,0) rectangle (9.8,5.5);
\draw(0,5.5) node[anchor=south west] {\scriptsize \sc Initialization};
\draw(3,5.5) node[anchor=south] {\scriptsize \sc Familiarization};
\draw(7.5,5.5) node[anchor=south] {\scriptsize \sc Stabilization};
% horizontal axis
\draw[->] (0,0) -- (10,0) node[anchor=north] {$t$};
\draw(5,-0.1) node[anchor=north] {\scriptsize Duration of interaction};


% vertical axis
\draw[->] (0,0) -- (0,6) node[anchor=east] {};
\draw(-0.8,3) node[rotate=90,anchor=south] {\scriptsize Normalized level of anthropomorphic effects};

\draw (-0.05, 3) -- (0.05, 3) node[anchor=east] {\scriptsize $\text{ICA}_{\mathcal B}$};
\draw (-0.05, 4.1) -- (0.05, 4.1) node[anchor=east] {\scriptsize $\text{ICA}_{\mathcal A}$};
\draw (-0.05, 0.6) -- (0.05, 0.6) node[anchor=east] {\scriptsize $\text{ICA}_{\mathcal C}$};

% vertical axis - end
\draw[->] (9.8,0) -- (9.8,2) node[anchor=east] {};
\draw (9.8, 0.8) node[anchor=west] {\scriptsize SLA$_\mathcal{E}$};
\draw (9.8, 1.4) node[anchor=west] {\scriptsize SLA$_\mathcal{D}$};
\draw (9.8, .2) node[anchor=west] {\scriptsize SLA$_\mathcal{F}$};


\draw[<-] (0.65,5) -- (0.8,5.2) node[anchor=east] {};
\draw (0.9,5.3) node[anchor=west] {\tiny \it novelty effect};


\draw[dotted] (0, 5) -- (6.2,5);
\draw[dotted] (0, 3) -- (6.2,3);
\draw[<->] (6.1,3) -- (6.1,5) node[anchor=east] {};
\draw (6.2,4) node[rotate=90, anchor=north] {\tiny Expectation mismatch};

\draw[<-] (1.7,4.4) -- (3.2,4.1) node[anchor=east] {};
\draw[<-] (2.85,3.3) -- (3.2,4.1) node[anchor=east] {};
\draw (3.2,4.1) node[anchor=west] {\tiny \it disruptive behaviors};
%%%%%
%% CURVES
%%%%
\begin{scope}[yscale=-1,shift={(-0.125,-0.4)}]

% output of inkscape2tikz
\path[draw=black]
    (0.1250,-2.5620) .. controls (0.1451,-3.7193) and (0.4645,-4.5602) ..
    (0.7044,-4.5633) .. controls (0.8413,-4.5633) and (0.9599,-4.5104) ..
    (1.0794,-4.3971) .. controls (1.1989,-4.2841) and (1.3191,-4.1185) ..
    (1.4588,-3.9181) .. controls (1.5287,-3.8183) and (1.5610,-4.1413) ..
    (1.6381,-4.1420) .. controls (1.7378,-4.1420) and (1.6515,-3.6434) ..
    (1.9554,-3.2280) .. controls (2.1466,-2.9667) and (2.3889,-2.7023) ..
    (2.6819,-2.4292) .. controls (2.7551,-2.3607) and (2.7727,-2.8119) ..
    (2.8771,-2.8180) .. controls (2.9742,-2.8180) and (2.9594,-2.2108) ..
    (3.1665,-2.0209) .. controls (3.3340,-1.8673) and (3.5379,-1.7527) ..
    (3.7508,-1.6236) .. controls (5.8366,-0.4852) and (8.0977,-0.2106) ..
    (10.1250,-0.1860);
\path[draw=black, dashed]
    (0.1250,-3.6924) .. controls (0.1103,-4.0298) and (0.4645,-4.5602) .. 
    (0.7044,-4.5633)
    (3.7508,-1.6236) .. controls (4.9579,-0.9555) and (8.1358,-0.8261) .. 
    (10.1250,-0.7946);
\path[draw=black,dashed]
    (0.1250,-0.1953) .. controls (0.1804,-3.3871) and (0.4645,-4.5602) .. 
    (0.7044,-4.5633) .. controls (0.8413,-4.5633) and (0.9599,-4.5104) .. 
    (1.0794,-4.3971)
    (3.7508,-1.6236) .. controls (4.7654,-0.8505) and (6.5955,0.3538) .. 
    (10.1250,0.4062);

\end{scope}

\end{tikzpicture}

\caption{Dynamics of anthropomorphism. We distinguish three main phases:
\emph{initialization}, \emph{familiarization} and \emph{stabilization}. In the
pre-interaction phase, users build an \emph{initial capital of
anthropomorphism} (ICA). Once the interaction starts, the level of
anthropomorphism increases due to the \emph{novelty effect}, and then decreases
to reach a \emph{stabilized level of anthropomorphism} (SLA).
During the interaction, unpredicted behaviors of the robot (\emph{disruptive
behaviors}) locally increase the level of anthropomorphism.}
\label{fig:dynamics}
\end{figure*}

So far, the HRI community has not much investigated how anthropomorphism in
human-robot interactions evolves over time (during the process of
\emph{adopting} a robot, for instance): we propose to go beyond the traditional
perception of anthropomorphism in robotics as a static feature that once
observed during a short-term interaction reflects a sustaining social effect.
Based on an extensive literature review and our own work \fxfatal{Summarize
these findings in a specific section!}, we believe that the social phenomenon
is not always be the same but evolve over time, along with growing interaction
and experience with the robot.


The model of anthropomorphism we propose (Figure~\ref{fig:dynamics}) represents
how the level of anthropomorphic effects (\ie observable manifestations of
anthropomorphism, as defined at section~\ref{sec:intro}) evolves over a
long-term human-robot interaction. By long-term interaction, we mean direct
(non-mediated), repeated interaction with the same robot, over (at least) several
days. The nature of the interaction (goal-directed, entertainment,...) may vary.

The model uses a \emph{normalized} level of anthropomorphic effects: because
anthropomorphic effects are not quantified on an absolute scale, we present
them as a normalized value, that span from a minimum (no anthropomorphic
effects) to a maximum (corresponding to the novelty effect peak on
Figure~\ref{fig:dynamics}). The actual maximum value of anthropomorphic effects
is strongly correlated to the human, the robot and other factors we introduce
below. Hence, the model we propose only focuses on the general \emph{shape} of
the level of antropomorphism over time, \ie the general dynamics of
anthropomorphism.

The model takes into account the duration of the interaction, the nature of the
interaction, as well as acquired experience and familiarization mechanisms: We
also propose to formally introduce a so-called \emph{novelty effect} that
models the first phase of human-robot interaction, and during which specific
anthropomorphic effect are observed.

\subsection{Three phases}
\label{sec:phases}

We distinguish three main phases that describe the evolution of the
anthorpomorphic effects in a long-term human-robot interaction. They are
depicted in different shades on Figure~\ref{fig:dynamics}.

First, the \emph{initialization} phase. During this short phase (from a couple
of seconds to a couple of hours), we observe an increased level of
antrophomorphism, from an \emph{initial capital of anthropomorphism}
(detailled in the next section) and a peak of antropomorphic manifestations
that correspond to the maximum of the \emph{novelty effect}.
Section~\ref{sec:initialization} details this first phase.

The second phase, \emph{familiarization}, lasts longer (up to several days) and
models the process of the human getting acquainted to the robot: by observation
and interaction, the human builds a model of the robot's behavior that allows
him/her to predict the robot's actions. We observe a decrease of
anthropomorphic effects during this phase, that we explain by the acquired
ability to predict the behavior of the robot: the initial apparent behavioral
complexity vanishes, and the robot is considered more and more as a machine.
Section~\ref{sec:familiarization} discusses the second phase.

The last phase is the \emph{stabilization} phase. The level of anthrpomorphic
effects tends to stabilize over a longer time, to reach a \emph{stabilized
level of anthropomorphism} (SLA). The SLA may be null (no anthropomorphic
effects observed anymore), but it may also remain at an higher level.  This
third phase, as well as the \emph{stabilized level of anthropomorphism}, are
discussed in section~\ref{sec:stabilization} below.


\subsection{Initial Capital of Anthropomorphism}
\label{sec:ica}

	Initially, there is a given potential that a robot will be anthropomorphized. Our proposed function to model the dynamics of anthropomorphism starts with this what we call \textit{initial capital of anthropomorphism} (ICA) at time point $t_{0}$, which describes the first (real or imagined) contact to the robot (see Figure \ref{fig:dynamics}). Time point $t_{0}$ can temporally be before the first real physical interaction with the robot, for instance, when a person learns about the existence of vacuum-cleaning robots and imagines using one (\textit{e.g.} when one watches an advertisement of the robot, or observes one at a trade show). In this stage of "pre-interaction", people form initial expectations toward the robot and imagine how they will use / interact with it. Time point $t_{0}$ can be understood as duration of interaction = 0 and user experience = 0. How can we hypothetically quantify the ICA on a normalized scale of anthropomorphism? For this, we suggest, what we call the \textit{"Three P's"}. These are three main factors that \textit{a priori} determine the potential to anthropomorphize a robot:
	
\begin{enumerate}

	\item The \textbf{personality} of the human user: Psychological characteristics / determinants that influence a person's tendency to anthropomorphize artifacts, see \cite{epley_seeing_2007}.
	
	\item The human user's \textbf{perception} of the robot: Characteristics of the robot's form, behavior, and interaction modalities (anthropomorphic design), see \cite{fong_survey_2003}.
	
	\item The real or imagined \textbf{purpose} of the robot: The task context and role in which the robot is used / experienced (environmental context), see \cite{joosse_what_2013}.

\end{enumerate}	

	The ICA comprises some hypothetical values for each of the \textit{"Three P's"}, such that different ICA values can be obtained, given the robot, human user, and environmental context.
	For \textbf{personality}, we suggest to apply Epley \textit{et al.}'s psychological \textit{"Three Factory Theory"} of anthropomorphism. For instance, children generally tend to anthropomorphize objects more than adults. Also, a person who lacks social connection is said to be more likely to anthropomorphize. Both aspects would increase the ICA. This means that, one and the same robot used in a different context or by a different user, can lead to a different ICA.
	
	For \textbf{perception}, we understand that a robot that follows an anthropomorphic design (e.g. NAO) leads to a higher ICA than a rather functional robot (e.g. Roomba). Also, a robot that displays facial expressions would increase the ICA. However, \hl{as discussed before} a classification of the "amount" of anthropomorphic design in a robot, as for instance suggested by Fong \textit{et al.} \cite{fong_survey_2003}, can be difficult.
	
	For \textbf{purpose}, we propose that the real or imagined context in which a robot is used, impacts how far the robot will be attributed human-social characteristics. We	draw on findings such as presented in Joosse \textit{et al.}. The authors showed that when the same robot (NAO) is used in a different task context (cleaning task \textit{vs.} tour guide), this influences the perception of the "personality" of the robot. In general, we think that a robot which is (imagined to be) used in a social, entertaining or playful context leads to a higher ICA than a robot which is used for a serious task (security, rescue, etc.). This idea receives support from \hl{XX (Kiesler / Goetz?)} work that revealed that people prefer a serious robot for serious tasks and a less serious robot for more playful tasks \hl{REF}. Also, we suggest that the environmental context in which people experience and interact with the robot impacts the ICA. When several people who might be friends interact simultaneously with the robot this might lead to an increased ICA \hl{study: people are more emotional when watching TV in company than when watching TV on their own}.

\subsection{Anthropomorphism during Initialization Phase}
\label{sec:initialization}

\paragraph{The Novelty Effect}
\label{sec:noveltyeffect}

\subsection{Anthropomorphism during Familiarization Phase}
\label{sec:familiarization}

\paragraph{Disruptive behaviors}
\ref{sec:disruptive}

\paragraph{Expectation mismatch}

\subsection{Anthropomorphism during Stabilization Phase}
\label{sec:stabilization}

\paragraph{Stabilized Level of Anthropomorphism (SLA)}

\fxnote{Note that ICA and SLA are NOT correlated}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				DISCUSSION
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:discussion}

The model of anthropomorphism we propose is still a work in progress. In
particular, its implications regarding the design of (social) robots and
human-robot interaction are still to be refined.

In this section, we discuss more speculative aspects and hypothesis that follow
from the model. These aspects would require further investigation and
experimental support to be validated.

\subsection{Anthropomorphism and Cognitive Models}
\label{sec:cognitivemodel}

\begin{figure}[htb]
\centering
%\resizebox{\linewidth}{!}{
\begin{tikzpicture}[scale=0.8, transform shape]
\baselineskip=8pt

% horizontal axis
\draw[->] (0,0) -- (10,0) node[anchor=north] {$t$};
% labels
\draw   (2,0) node[anchor=north] {Phase I}
        (5,0) node[anchor=north] {Phase II}
        (8,0) node[anchor=north] {Phase III};

\draw[dotted] (3.5, -0.5) -- (3.5,6);
\draw[dotted] (6.5, -0.5) -- (6.5,6);

% vertical axis
\draw[-|] (0,0) -- (0,6) node[anchor=east] {};
% Us
\draw[thick] (0,0) -- (1,2) -- (3,2) -- (4,4) -- (6,4) -- (7,6) -- (10,6);

\draw (2.2,2) node[align=center] {\scriptsize{sub-cognitive}\\\scriptsize{anthropomorphism}}; %label
\draw (5,3.85) node[align=center] {\scriptsize{projection of existing}\\\scriptsize{mental models}\\\scriptsize{\it (familiarity)}}; %label
\draw (8.5,5.85) node[align=center] {\scriptsize{adapted mental model} \\ $\to$ \scriptsize{adapted interaction}\\\scriptsize{\it (antropomorphic or not)}}; %label

\draw (2.2,1) node[align=left] {\tiny{\it observation (shape, motion, sound)}}; %label
\draw (5.2,3) node[align=left] {\tiny \it observation (interactive behavior) \\ \tiny \it or short interaction}; %label
\draw (7.8,5) node[align=left] {\tiny \it contextualized interaction}; %label

\end{tikzpicture}
%}
\caption{The three cognitive phases of anthropomorphism: Phase I is the instinctive,
sub-cognitive identification of living peers. {\it Empathy} [TO DISCUSS] is characteristic
of this stage. After longer observation or short, uncontextualized interaction
(typically, a lab environment), the user enters Phase II: the user projects a
mental model he/she is already familiar with onto the robot. This leads to
expectation regarding the cognitive abilities of the robot. After longer {\it
contextualized} interaction (typically, at home), the user enters Phase III of
anthropomorphism: the user recomposes an accurate mental model of the robot,
based on experience. This leads to adapted interaction modalities, that may
still be anthropomorphic, or not.}
\label{fig:cognitivemodel}
\end{figure}

Figure~\ref{fig:cognitivemodel} offers a cognitive perspective on the dynamics
of anthropomorphism presented in the previous section.

The first cognitive phase we identify that contribute to anthropomorphism is
actually \emph{pre-cognitive}. In~\cite{Rosenthal-vonderPutten2013Neural},
Rosenthal-von der Pütten et al. investigated the neural correlates of emotional
reactions of human towards robot or other human that showed comparable
responses. \fxfatal{Complete that. Reference to the pleo paper}.

After a longer observation period (typically including complete action
sequences of the robot) or short interaction (touching, short talk like
greetings), the human enters the cognitive phase II: in this phase, the human
starts to build a behavioral and cognitive model of the robot that would
support both the observed and imagined capabilities of the robot. Based on the
\emph{familiarity thesis}\fxfatal{citation!}, we suggest that the human first
projects onto the robot mental models of similar agents he/she is already
familiar with. This may range from animals to adults, through pets and
children. We hypothesise that the nature of the projected mental model, as well
as how deep the human engage in this projection, are driven by the same
parameters as we presented for the \emph{initial capital of anthropomorphism}
(section~\ref{sec:ica}, p.\pageref{sec:ica}).

We identify a further transition to the cognitive phase III after a
\emph{contextualized} interaction. A \emph{contextualized} interaction is
\emph{explicitly purposeful} (the purpose of the interaction, be it purely
entertainment, is explicit and conscious for the human), and takes place in an
environment that fosters a stronger cognitive (and possibly affective)
commitment from the human in the interaction (typically, at home). During this
interaction, the human iteratively restate and reshape its behavioral and
mental model of the robot (\emph{how does the robot react to such and such
situation/input? what does the robot knows about me? about itself? about our
environment? what can the robot learn?}, etc.).

This mental process heavily depends on the human understanding of the robot
inner working, as well as his/her own tendency to anthropomorphize (the
\emph{personality} in ICA factor), but at this stage, the \emph{perception} of
the robot (its shape for instance) and its intended \emph{purpose} play only a
minor role. It is mostly a human-centric process.

\paragraph{Relation to the model of anthropomorphism} It must be noted that the
three cognitive phases we introduce here do not match the
\emph{initialization}, \emph{familiarization} and \emph{stabilization} phases
introduced at~\ref{sec:phases}: in particular, cognitive phases I and II are
both included in the \emph{initialization} phase of the anthropomorphism model.

Sub-cognitive anthropomorphism typically \emph{initiates} the novelty effect by
rapidly engaging the human in the interaction through this initial projected
\emph{agency}, whereas cognitive phase II (projection of familiar mental
models) supports the novelty effect by inducing beliefs that the robot is set
up with possibly complex cognitive abilities.

The cognitive phase II also overlaps with the \emph{Familiarization} phase: as
(s)he get used to the robot, we hypothesize the human restate and adapt its
cognitive model of the robot by iteratively reshaping pre-existant, familiar
models until it provides a satisfying support to explain and justify the
observed robot behavior.

A \emph{stable level of anthropomorphism} is reached when the adaptation
process depicted in cognitive phase III reached a stable state, \ie the human
experience with the robot is correctly supported by the cognitive model the
human has built.

\paragraph{Limits} This discussion on the cognitive correlates of the dynamics
of anthropomorphism are speculative, and only indirectly supported by
experimental evidence. New experiences need to be designed to specifically test
these hypothesis.\fxnote{...}

\subsection{Effect of Context of Use and Purpose of the Robot}
\label{sec:8.1}
Frederic: role of uselessness


\begin{description}
	\item[\textbf{Hypothesis 1}] A person's tendency to anthropomorphize a robot is impacted by the context of use and purpose of the robot. A social context and purpose of the robot increases anthropomorphism. \textit{(context and purpose of the robot)}
\end{description}



\subsection{Effect of Time and Familiarization}
\label{sec:8.2}

	The \textit{context of use} is related to the purpose (and functionality) of the robot and influences the user interaction experience. With \textit{time}, we refer to long-term interaction with the robot, which is related to what has been described as 'novelty effect' but also accounts for the user getting used to the robot. Consequently, we propose that anthropomorphism is not static but likely to change, due to what we call \textit{dynamics}, in space and time.


	As outlined in section \hl{XX}, the tendency to anthropomorphize is motivated by a person's wish to make sense of an agent which might be difficult to understand (in its functionality or behavior, for instance). In turn, a user might ascribe intentions or emotions to the system because the systems output was unexpected for the user. Based on this explanation, we estimate that when the user has familiarized herself / himself with the system, thus reached the point of when the system is usable and explainable, the tendency to anthropomorphize decreases. Therefore, our second hypothesis is as follows: 

\begin{description}
	\item[\textbf{Hypothesis 2}] A person's tendency to anthropomorphize a robot decreases over time and with growing experience the person has with the robot. \textit{(familiarize oneself with the robot)}
\end{description}	
	

Given our first hypothesis from above, this might not hold over all contexts; more concretely, probably not in a social context of usage.


	Smart innovative devices, such as personal domestic robots, might demand from a human user spontaneous usage of an unfamiliar system. Such situations will require that a user should be able to build up a mental model quickly, which particularly holds for novice users \cite{schmitz_concepts_2011}.

	Eddy \textit{et al.} points out that familiarity increases the tendency to anthropomorphize \cite{eddy_attribution_1993}.

	"As shown in several psychological experiments [13,24] and pointed out by Watt [25], familiarity may also ease social acceptance and even tend to increase people's tendency to anthropomorphize [16]." \cite{duffy_anthropomorphism_2003}

\subsection{Personal characteristic effects in anthropomorphizing}
\label{sec:8.3}

\subsection{Role of disruptive behaviors}
\label{sec:disruptive}

Common observation of naive people (children or adults) interacting with robots
shows that unexpected behaviors of the robot has a notable impact on
interaction.

During a normal interaction with the robot, the user iteratively refine its own
model of the behavior of the robot. As explained in previous sections, as the
user improves its model of the robot actions, it also improves its ability to predict
the actions and thus, the user tends to anthropomorphize less.

We emit the hypothesis that an unexpected robot behavior leads the user to
suddently restate its behavioral model of the robot and will temporarly lead to
an increase of the level of anthropomorphism (depicted by the spikes on
Figure~\ref{fig:dynamics}).

\begin{figure}
\begin{center}
    \begin{tabular}{ | >{\centering\arraybackslash}m{1.5cm} | >{\centering\arraybackslash}m{2cm} | >{\centering\arraybackslash}m{2cm} |}
    \hline
     & Unplanned by the robot & Planned by the robot \\ \hline
    Perceived as non-intentional & case I  & case IIIa  \\ \hline
    Perceived as intentional &  case IIIb & case II  \\ \hline
    \end{tabular}
\end{center}
\caption{
    Behaviors of the robot that are unexpected by the user may be intentional
    (the robot has planned the behavior) or not (typically, a failure:
    misdetection, bug,...). Independently of that, the behavior may be
    \emph{perceived} by the user as intentional or not.}
\label{fig:perceptionUnexpectedBehavior}
\end{figure}

When talking about \emph{unexpected robot behaviors}, several distinct cases
must be considered, summarized in Table~\ref{fig:perceptionUnexpectedBehavior}.

If the unexpected behavior is not planned, and perceived as such by the human
(case I), the human can interpret that the robot is faillible. If the robot
explicitly states its failure (for instance, by saying ``I'm lost!''), the
behavior is then called \emph{transparent} \fixme{cite here, Julia?}, and the
user may besides hypothesize that the robot has \emph{introspective}
capabilities, which in turn may leads to higher anthropomorphism level.  On the
contrary, if the robot shows no sign of recognizing its own failure, the user
may ascribe a lower level of anthropomorphism to the robot.

In case II, the robot voluntary executes a behavior that is unexpected by the
human, and the human perceives it rightfully as an \emph{intentional} behavior.
For instance, the human asks the robot to go somewhere, and the robot refuses,
saying ``I do not want to go there''. In that case, we expect to see an
increase of anthropomorphism attribution due to the human ascribing
intentionality to the robot.

Case IIIa and IIIb correspond to misinterpretations of the robot behavior. Case
IIIb may actually lead to increased level of anthropomorphism since the human
will (wrongfully) attribute intentionality to the robot, while case IIIa is
expected to lead to a lower anthropomorphism level.  However, in those two
cases, the next occurrence of an expected behavior, if correctly interpreted
(case I or II), is likely to lead to stronger effects due to a larger delta
between expectations and actual observed behavior.

%% experience -> unexpected behavior should not impact the interaction child-robot BEFORE the theory of mind is established!



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				CONCLUSION
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusion}
\label{sec:9}


	Anthropomorphism is a social phenomenon, which seems to be natural on one side and very complex on the other side. It is a mechanism within oneself that makes a human observer think and treat a non-human agent as if it would have some human (social) characteristics, and ascribe to it intentions, emotions, or thoughts, for instance. In accordance with other researchers, we also think that the term is sometimes misused or misunderstood \cite{duffy_anthropomorphism_2002}. Concerning robotics, we do not think that we can speak of anthropomorphism when a person simply refers to physical parts of a robot using terms that describe a human body, such as arm, head, fingers, etc.. We believe that this is not anthropomorphism in its true sense because the person might simply take advantage of the physically resembling shape instead of truly ascribing human (social) characteristics to the robot.



\section*{Acknowledgements}
AJung Moon, Aude Billard.\\

This research was supported by the Swiss National Science Foundation through
the National Centre of Competence in Research Robotics.

\section{Bibliography}
\bibliography{anthropomorphism}   % name your BibTeX data base

\hrule
\vspace*{.1in}
Authors' names and contact information: Julia Fink {\tt julia.fink@epfl.ch}, Séverin Lemaignan {\tt severin.lemaignan@epfl.ch}, Pierre Dillenbourg {\tt pierre.dillenbourg@epfl.ch}, CHILI Lab, EPFL, Lausanne, Switzerland.
\end{document}

