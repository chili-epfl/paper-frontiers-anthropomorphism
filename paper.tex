\documentclass{frontiersSCNS} % for Science articles



\usepackage{graphicx}
\graphicspath{{figs/}}
\usepackage{tikz}
\usetikzlibrary{shapes}
\usetikzlibrary{svg.path}
%
\usepackage{amsmath} 
\usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
\usepackage{color, soul}
\usepackage{url}
\usepackage{multirow}
\usepackage{array}
\usepackage{fixltx2e}
\usepackage{textcomp}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\floatstyle{plaintop}

\usepackage{paralist} % inparaenum

\usepackage[bookmarks]{hyperref}

\usepackage[draft, nomargin, marginclue, footnote]{fixme}
\fxsetup{targetlayout=color}

\usepackage{xspace}
\newcommand{\eg}{\textit{e.g.}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\ie}{\textit{i.e.}\xspace}
\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\vs}{\textit{vs.}\xspace}

\usepackage{xifthen}% provides \isempty test

% use either \Ant or \Ant[R,H,C,...]
\newcommand{\Ant}[1][]{%
      \ifthenelse{\isempty{#1}}%
        {$\mathcal{A}$}
        {$\mathcal{A}(#1)$}
}

\newcommand{\AntNorm}[1][]{%
      \ifthenelse{\isempty{#1}}%
      {$\widehat{\mathcal{A}}$}
      {$\widehat{\mathcal{A}}(#1)$}
}


% for use inside a math environment
\newcommand{\ant}[1][]{%
      \ifthenelse{\isempty{#1}}%
        {\mathcal{A}}
        {\mathcal{A}(#1)}
}

\newcommand{\antNorm}[1][]{%
      \ifthenelse{\isempty{#1}}%
      {\widehat{\mathcal{A}}}
      {\widehat{\mathcal{A}}(#1)}
}

\newcommand{\ICA}{{$\mathcal{A}_0$~}}
\newcommand{\SLA}{{$\mathcal{A}_\infty$~}}
\newcommand{\sla}{{\mathcal{A}_\infty}}
\newcommand{\AntMax}{{$\mathcal{A}_{max}$~}}
\newcommand{\antMax}{{\mathcal{A}_{max}}}

\hyphenation{com-mon-ly}
\hyphenation{an-thro-po-mor-phism}
\hyphenation{an-thro-po-mor-phic}

\copyrightyear{}
\pubyear{}

\def\journal{Cognitive Science}
\def\DOI{}
\def\articleType{Research Article}
\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Fink {et~al.}} 
\def\Authors{Julia Fink\,$^{1*}$, S\'{e}verin Lemaignan$^{1}$, Claire Braboszcz$^{2}$ and Pierre Dillenbourg$^{1}$}
\def\Address{$^{1}$Computer-Human Interaction in Learning and Instruction (CHILI) \\ Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL) \\ CH-1015 Lausanne, Switzerland \\
\vspace{0.25cm}
$^{2}$Laboratory for Neurology and Imaging of Cognition (LabNIC) \\
Universit\'{e} de Gen\`{e}ve \\ CH-1211 Gen\`{e}ve, Switzerland 
}
\def\corrAuthor{Julia Fink \vspace{1mm}}
\def\corrAddress{EPFL - CHILI, RLC D1 740, Station 20, CH-1015 Lausanne, Switzerland}
\def\corrEmail{julia.fink@epfl.ch}


\begin{document}
\onecolumn
\firstpage{1}

\title[Dynamics of Anthropomorphism]{Dynamics of Anthropomorphism in Human-Robot Interaction}
\author[\firstAuthorLast ]{\Authors}
\address{}
\correspondance{}
\extraAuth{}
\topic{The Uncanny Valley Hypothesis and Beyond}

\maketitle


\begin{abstract}

\textit{Anthropomorphism} -- people's tendency to perceive human-like
characteristics in non-human agents -- is a phenomenon that is often
studied from the sole perspective of the human-like \emph{design} of robots.

By building upon experimental results from several studies, a comprehensive
synthesis of literature, as well as insights from social psychology,
cognitive science, and neuroscience, this article proposes to extend our current
understanding of anthropomorphism. By doing so, we propose a \textbf{formal model} that defines a
\textbf{clear terminology} and accounts for the \textbf{non-monotonic dynamics} of
the phenomenon. We further relate the observed \emph{effects} of anthropomorphism to
their \textbf{underlying cognitive precursors}.

We examine several \textbf{factors} that determine anthropomorphism, namely the
design of the non-human agent, the individual psychological determinants of the
human user, and the context of use. Moreover, we discuss several \textbf{episodes of
interaction} that influence the anthropomorphic projections on the robot, like
the \textbf{novelty effect}, the role of \textbf{familiarization} and the
impact of \textbf{disruptive behaviors}.

Finally, the article also discusses techniques and scenarios to measure anthropomorphism,
and we conclude with a few suggestions on how others can apply our model to
better describe people's tendency to perceive human-like characteristics in non-human
agents.


\tiny
 \keyFont{ \section{Keywords:} Anthropomorphism, Design, Human-Robot Interaction, Social Issues in Robotics, Acceptance of Robots}

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%		INTRODUCTION & OVERVIEW
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}
\label{sec:intro}

The Uncanny Valley hypothesis \citep{mori_uncanny_1970} proposes that human-like
designs of objects and non-human agents can evoke both positive and negative
feelings in the human observer / user. A positive valence reflects the
experience of emotional engagement with and feelings of empathy for the
non-human agent \citep{cheetham_human_2011}. This in turn may lead to an
effective (human-like and human-social) interaction with the non-human agent,
and increase people's acceptance of it. 

A phenomenon that is often studied related to this is \textbf{anthropomorphism}.
Along this line, this article aims at fostering a better understanding of
anthropomorphism (noted \Ant in this paper) in human-robot interaction by
considering the phenomenon as a whole. Robotics researchers often tend to
believe that anthropomorphism only describes a static set of human-like features
of a robot (like shape, speech capabilities, facial expressions, etc.). We refer
to these characteristics as the \emph{anthropomorphic design} of the
robot~\citep{fink_anthropomorphism_2012}, and propose that
\emph{anthropomorphism} in general refers to a \emph{social phenomenon} that
emerges from the (real or imagined) \emph{interaction} between a non-human agent
(\eg a robot) and a human~\citep{persson_anthropomorphism_2000}. According
to~\cite{epley_when_2008}, anthropomorphism includes that the human perceives,
for instance, emotional states, motivations, or intentions in the non-human
agent, and tends to ascribe those qualities to it.  As such, the dynamic and
socio-cognitive dimensions of anthropomorphism are essential to understand the
complex bonds that human users build with artificial agents such as robots.


\subsection{A few results from the field}
\label{sec:field-results}

To support the reflection on variances and dimensions of anthropomorphism, it may be 
useful to consider a few experimental
results. We studied anthropomorphism in several short- and long-term
human-robot interaction studies that we carried out with embodied robots, both
in ecologically valid real-world environments and controlled lab settings. Those
experiments are presented in details in previously published
articles~\citep{fink_anthropomorphic_2012, fink_living_2013, fink2014which,
lemaignan2014dynamics}. We only highlight here a few qualitative results that
underline the complexity of the phenomenon.

\begin{figure}[b]
        \centering
        \begin{subfigure}[t]{0.48\columnwidth}
                \includegraphics[height=7cm]{roomba-activities}
                \caption{Activities related to Roomba, \textit{n = 9 households}}
                \label{fig:roomba-activities}
        \end{subfigure}%
        \hspace{0.5cm} 
        \begin{subfigure}[t]{0.48\columnwidth}
                \includegraphics[height=7cm]{roomba-ratings}
                \caption{People's perception of Roomba, \textit{n = 15
                participants}}
                \label{fig:roomba-perception}
        \end{subfigure}
    \caption{Usage and perception of the Roomba vacuum-cleaning robot over a 6
    months period. Qualitative data suggest that people's activities related to
    the robot as well as their perception of the robot change over time.}
    \label{fig:roomba}
\end{figure}

Figures~\ref{fig:roomba-activities} and~\ref{fig:roomba-perception} give a first
perspective on how naive users interact and perceive robots over a long period
of time. Here, \emph{Roomba} vacuum cleaning robots were given to nine
households for a 6-months period. The aim was to explore how people use and
perceive the robot over time, and how they generally live with the Roomba in
their home. At various time points, users were asked to rate their perception of
different features of the robot on a 7-point rating scale. As
Figure~\ref{fig:roomba-perception} shows, some features remained stable over
time (\emph{ease of use} and \emph{fun}), and others decreased: the perceived
\emph{usefulness}, \emph{intelligence} and \emph{impact} on their household.
\emph{intelligence} and \emph{impact} reflect the cognitive engagement of the
user towards the machine: we can assume that one does not care to engage in a
(cognitive) interaction with an artifact perceived as non-intelligent and with
no impact on one's life (and the level of activity pictured in
Figure~\ref{fig:roomba-activities} qualitatively confirms this intuition). Even
if one can argue that the Roomba is not designed to foster interaction, it
raises a first question: how to sustain engagement between a robot and a human
over a long period of time? And, as a pre-requisite to answer, do we actually
understand the psychological phenomenon, and can we effectively account for the
dynamics of these interactions?

Those questions are certainly not new, but paradoxically, while anthropomorphism
is a commonly discussed trait of human-robot interaction, it appears
that we lack formal grounds and models that would account for the long-term
dynamics of these interactions.

\begin{figure}[b]
        \centering
        \begin{subfigure}[b]{0.48\columnwidth}
                \centering
                \includegraphics[width=0.75\textwidth]{ranger}
                \caption{Interaction scenario of the \emph{Ranger} domino study:
                the robot toy box Ranger transports domino tiles between the two
                children}
                \label{fig:ranger-expe}
        \end{subfigure}%
        \hspace{0.5cm}
        \begin{subfigure}[b]{0.48\columnwidth}
            \includegraphics[width=\textwidth]{correlation}
            \caption{\emph{Engagement actions} vs \textit{subjective anthropomorphic
                perception} evidence one cluster of
                high-anthropomorphizers/low-interactors and another group of children who
                interact more with the robot and anthropomorphize it less.}
            \label{fig:qualitative-score}
        \end{subfigure}
        \caption{Children's interaction with Ranger, and their anthropomorphic
        projections onto the robot. Overall, large variations of both children's
        behavior and their perception of the robot were found but seemed to be
        correlated to each other.}
    \label{fig:ranger}
\end{figure}


Figure~\ref{fig:qualitative-score} calls for other initial remarks. This diagram
shows data from a (yet unpublished) study in which 13 pairs of children (4-5
years old) played for about 20 minutes a Domino game with a robot toy box (the
robot was tasked to carry domino pieces from one child to the other,
Figure~\ref{fig:ranger-expe}).  The $x$-axis represents the number of social
interactions between the children and the robot (like talking to the robot or
showing objects), based on video annotations. On the $y$-axis, we have a
synthetic qualitative measurement of anthropomorphic projections onto the robot,
based on two interviews with the children. The correlation between both these
values is significantly \emph{negative}: the more the children engaged into
interaction, the less prone to anthropomorphic projections they were. This
diagram also highlights an interesting cluster of children who did not interact
much with the robot, and still reported a strong anthropomorphic perception of
the robot.

These results may seem counter-intuitive at first sight, and illustrate that the
mechanisms that relate anthropomorphism to adoption and engagement are
non-trivial. In section~\ref{sec:cognition-neuroscience}, we sketch a model of
the cognitive correlates of anthropomorphism that partially account for these
results.


\subsection{Towards a formal understanding of anthropomorphism}

These first remarks lead to the main question we attempt to address in this
article: how can we understand \emph{anthropomorphism} as a whole, and in such a
way that it supports or improves human-robot interaction?

We propose to discuss anthropomorphism from three
complementary perspectives: 

First, by reviewing what anthropomorphism actually \emph{means}: besides an
\emph{artifact-centered} understanding that explains anthropomorphism from the
human-like design of the non-human artifact, it seems important to explicit the
social component, namely a \emph{human-centered} understanding, of
anthropomorphism.

Second, we propose a model, called the \textit{Dynamics of Anthropomorphism} to
understand how anthropomorphism evolves over time
~\citep{lemaignan2014dynamics}.  These dynamics are non-monotonic, and effects
like the \emph{novelty effect} play here a key role.

Finally, we adopt a third perspective on anthropomorphism by investigating its
\emph{cognitive correlates}. Several studies previously showed that we build
instinctive bonds with robots as soon as we attribute animacy, and we also know
from social psychology some of the mechanisms that lead to
\emph{familiarization}. We attempt here to ``connect the dots'', in order to
build a practical model of the cognitive stages we encounter in human-robot
interaction.


%\paragraph{Two hypotheses}
Our research question also translates to two
hypotheses, which structure the reflections of this article:

\begin{enumerate} 
\item ~A person's tendency to anthropomorphize a robot
    is based on several factors, including (but not limited to) (1) the
    design of the robot, (2) the personal characteristics of the human user,
    and (3) the context and situation of use. For instance, a social context
    and purpose of the robot increase anthropomorphism: \textit{anthropomorphism
    as a multi-factor phenomenon}.

\item ~A person's tendency to anthropomorphize a robot
    evolves in a non-linear way over time and with growing experience that the
    person has with the robot. For instance, a more experienced user will
    perceive the robot as more familiar and predictable, and in turn
    anthropomorphizes the robot less: \textit{anthropomorphism as a dynamic
    phenomenon}.

\end{enumerate}

\subsection{Article overview}

The remainder of this article is organized as follows.  According to the three
perspectives that we take, we first (in Section \ref{sec:anthropomorphism}) aim
to establish a common ground in the understanding of anthropomorphism. We review
literature from several relevant domains and integrate the different
explanations into an understanding of anthropomorphism as a multi-factor
phenomenon.  Based on this, Section~\ref{sec:our-ideas} introduces our initial
model of the \textit{Dynamics of Anthropomorphism}. This model describes the
variances and dynamics of people's tendency to anthropomorphize an artificial
agent, such as a robot.  Then Section \ref{sec:cognition-neuroscience} presents
a cognitive and neuroscience perspective on anthropomorphism to consolidate our
considerations and the proposed model.  This is followed by a discussion about
the limitations of our approach (Section \ref{sec:discussion}) and the existing
and alternative ways to measure anthropomorphism in human-robot interactions.
Finally, Section \ref{sec:conclusion} concludes this article and offers starting
points for further research on anthropomorphism and the effect of the human-like
design approach in robotics.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%		WHAT IS ANTHROPOMORPHISM
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Towards a unified understanding: What is anthropomorphism?}
\label{sec:definitions}

Literature on anthropomorphism is quite diverse. There exist different and
partly conflicting definitions of the term anthropomorphism, and that in
general, the \textit{terminology} is not clear. Probably as a result of this,
there also exist different understandings of the \textit{phenomenon} that the
term ``anthropomorphism'' describes.  In this section we will first give an
overview on the diversity of terms and then try to establish a common ground in
the understanding of anthropomorphism as a psychological phenomenon.

\subsection{Overview of the diverse understandings of anthropomorphism}

Naturally, conflicts in how terms are used lead to a diversity of understandings
of the phenomenon which is described.  One reason for this might be that
anthropomorphism is a phenomenon that is studied in very different domains that
might each integrate their own understanding, use the same term to refer to
different things.  Despite the fact that there is no commonly accepted
definition, the terms \textit{anthropomorphism}, \textit{anthropomorphic} or
\textit{human-like} are often used as if their meanings were clear and agreed
upon \citep{persson_anthropomorphism_2000}. It is even argued that these terms
might be misused \citep{duffy_anthropomorphism_2002,epley_when_2008}.  For
instance, some researchers refer to \textit{``the robot's level of
anthropomorphism''} \citep{bartneck_is_2007,feil-seifer_human-robot_2008},
whereas others disagree to such a statement because they understand that a
system or artifact itself does not \textit{``contain anthropomorphism''} but
only gives rise to the process of anthropomorphizing in a given user and
situation. Consequently, \cite{persson_anthropomorphism_2000} conclude that
anthropomorphism emerges in the \textit{interaction} between the technology and
the user, and has to be understood as such. We come back on this point in the
next section.


Another paradox is that, while human's tendency to anthropomorphize is commonly
observed, the phenomenon is at the same time still rather poorly understood
\citep{epley_seeing_2007}. The phenomenon itself has been found to be very
complex, sometimes subtle and as such hard to study
\citep{duffy_anthropomorphism_2002,epley_when_2008}. Besides, it is not clear
how to operationalize and measure anthropomorphism (we discuss this question
toward the end of this article, in Section \ref{sec:measuring}).

Depending on which definition of anthropomorphism is applied, not everything 
colloquially labeled as \emph{anthropomorphism} really is anthropomorphism.
For example, it is not always clear whether a person (may it be an adult or 
a child) who gives an anthropomorphic response, believes that the other agent really 
thinks or acts like a human or whether he/she is using anthropomorphism in a metaphoric 
sense \citep{leeds_childrens_1992}.
This call for explicitely stating what we mean when talking about anthropomorphism. 

Several attempts have been made to clarify what the psychological phenomenon
\emph{anthropomorphism} actually is.  From a psychology point of view,
\citet{epley_when_2008} explain what anthropomorphism is \textit{not}. For
instance, in their understanding, anthropomorphism does not include behavioral
descriptions of observable actions but it requires going beyond what is directly
observable. They also suggest that anthropomorphism does not merely entail
\textit{animism}, as animate life is not a \textit{uniquely} human-like
characteristic.\footnote{For the whole list and more details, the reader may
refer to the original work \citep{epley_when_2008}.}

As human-likeness itself is manifold and complex,
some researchers argue that there might not just be one single type of
anthropomorphism but different levels or gradations. For instance,
\citet{persson_anthropomorphism_2000} proposes to understand anthropomorphism as
a multi-layered phenomenon, namely \emph{primitive categorization},
\emph{primitive psychology}, \emph{folk-psychology}, \emph{traits}, \emph{social
roles}, and \emph{emotional anthropomorphism}. Correspondingly,
\citet{ruijten_introducing_2014} propose to understand anthropomorphism as a
continuum ranging from low to high human likeness, and to measure it as such.


\subsection{Terminology used in this article}

We use the term \textbf{anthropomorphism} to describe the \emph{psychological}
phenomenon, which arises in the \emph{social context} of an interaction between
a human agent and a non-human agent, in our case, a robot (see Figure
\ref{fig:anthropofig}). We use this term to refer to both people's tendency to
\textit{perceive} human-like characteristics, and to the tendency to
\textit{ascribe} or \textit{attribute} such human-like characteristics to the
agent or artifact. Besides, we call {\bf anthropomorphic effects} the
\emph{observable manifestations} of anthropomorphism, \ie the human's behaviors
and actions toward a non-human agent that reflect the underlying cognitive
process of anthropomorphizing.

However, despite the fact that ``anthropomorphism'' literally means ``human
form'' we propose that the term should \textit{not} be used to refer to the
\textit{form / design} of a non-human agent or artifact. To refer to an
imitation of human-like \textit{form / design} of artificial agents, we propose
to use the term \textbf{anthropomorphic design}. This explicit terminology
prevents the commonly encountered confusion between anthropomorphism as a
psychological, subjective phenomenon, and the external, objective factors that
\emph{influence} the phenomenon itself.

In the following, we might use the terms \emph{form} and \emph{design}
interchangeably. Note that the terms \textit{form} or {\it design} do not only
refer to the shape (how it looks like) but to the total expression of the
artifact~\citep{bartneck_shaping_2004}. \citet{disalvo_hug:_2003} argues that
\textit{form} includes the physical shape, materials, and behavioral qualities
of the product. The behavioral aspect is of special importance for interactive
systems that show some degree of autonomy (independence).  Several categories of
anthropomorphic form exist, with no common agreement on the borders and
transitions between those: anthropomorphic, zoomorphic, caricatured, functional
\citep{fong_survey_2003}.

\begin{figure}
    \centering
    \includegraphics[width=0.75\columnwidth]{anthropo.pdf}
    \caption{Anthropomorphism is a psychological phenomenon which arises in a
        social context, during an interaction between a human agent and a
        non-human agent. One can take two main perspectives when trying to
        explain anthropomorphism: a human-centered and an artifact-centered
        perspective (grey triangles). Several external factors influence the
        anthropomorphism phenomenon. Person- and artifact-related characteristics,
        but also related to the context of use as well as the actual time spent
        interacting with the robot (interaction history). [SEE
        FIG~\ref{fig:anthropofig-alt} FOR AN ALTERNATIVE FIGURE]}

    \label{fig:anthropofig}
\end{figure}

%
%\begin{figure}
%    \centering
%    \includegraphics[width=0.75\columnwidth]{in_our_heads.pdf}
%    \caption{[ALTERNATIVE TO FIGURE \ref{fig:anthropofig}] Anthropomorphism is a
%        subjective, psychological phenomenon which arises in a social context, during an
%        interaction between a human agent and a non-human agent. One can take
%        two main perspectives when trying to explain anthropomorphism: a
%        human-centered and an artifact-centered perspective.
%        Several external factors influence the anthropomorphism phenomenon.
%        Person- and artifact-related characteristics, but also related to the
%        context of use as well as the actual time spent interacting with the
%        robot (interaction history).}
%
%
%    \label{fig:anthropofig-alt}
%\end{figure}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%		WHY DO HUMAN ANTHROPOMORPHIZE
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Why do humans anthropomorphize?}
\label{sec:anthropomorphism}

Anthropomorphism is an interesting phenomenon because it tells us something
about the relationship between the human who anthropomorphizes, and the
non-human agent which is anthropomorphized. Though commonly observed, it still
appears controversial, at the same time, that humans tend to \textit{``see human
in the non- human''} \citep{epley_seeing_2007}.

As anthropomorphism arises in an interaction between a human and a non-human
agent \citep{persson_anthropomorphism_2000}, one can also take two main
\textit{perspectives} when trying to explain why humans anthropomorphize
\citep{lee_human_2005}: an artifact-centered perspective and a human-centered
perspective (see grey triangles in Figure \ref{fig:anthropofig}). It has to be
kept in mind that both perspectives are inseparable; they apply at the same
time, and we would like to present them here just as two different viewpoints on
the same phenomenon.

In the following we will only briefly present the artifact-centered perspective
to explain anthropomorphism. A review of anthropomorphic design of robots can
also be found in \cite{fink_anthropomorphism_2012}. Then, we provide a more
detailed review and synthesis of literature that applies a human-centered
perspective to explain anthropomorphism. Concretely, we integrate theories from
developmental psychology, cognitive science / neuroscience, and social
psychology to shed light on the question why humans anthropomorphize.


\subsection{Artifact-centered perspective on anthropomorphism}

The artifact-centered perspective explains anthropomorphism from the
ascertainable parts of the non-human agent, namely the anthropomorphic form of
it. This section deals with the question how far anthropomorphism can be
explained from the design of the artifact.  One of the most prominent working
hypothesis in this field is the Uncanny Valley hypothesis
\citep{mori_uncanny_1970}. In general, it is proposed that human-like designs of
robots can evoke both positive and negative feelings in a human user. 

The direction of causality in the artifact-centered view goes from the artifact
to the humans: the artifact (or a certain feature of it) \emph{encourages} the
human to anthropomorphize it.  This perspective assumes that humans directly
(mindlessly) respond to life-like and social cues that the non-human agent or
system emits \citep{nass_machines_2000}. Without thoughtful mental processing,
humans tend to simply apply stereotypes and heuristics to the non-human agent,
and in turn apply human-human social schemas and norms to the occurring
interactions.  \cite{takayama_perspectives_2012} proposes to refer to this
immediate (sometimes visceral) sense in a situation as \textit{in-the-moment},
compared to a more distanced cogitation and consideration which she calls
\textit{reflective}. As this distinction implies different cognitive processes,
it is more approriate to apply a human-centered perspective and we will come
back to it later, in section \ref{sec:cognitive-expl}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%		HUMAN-CENTERED PERSPECTIVE: SOCIAL PHENOMENON
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	

\subsection{Human-centered perspective on anthropomorphism}

In contrast to the artifact-centered perspective, in the human-centered
perspective the argumentation is that the human is self-motivated to
anthropomorphize the non-human artifact. As already mentioned, both these views
go hand in hand.

Humans tend to perceive human-like characteristics such as physical appearance,
emotional states, or inner mental states and motivations in non-human agents
that do not have these characteristics themselves, such as animals, natural
forces, religious agents, technological gadgets, or mechanical devices
\citep{epley_when_2008}.\footnote{According to \citet{epley_when_2008}, a
non-human agent can be anything that acts -- or is believed to act -- with
apparent independence.} One common reason for anthropomorphism is that by
perceiving some human-like characteristics in the non-human agent, this agent is
made more \emph{graspable}, \emph{understandable}, \emph{predictable}, and one
can feel \emph{more empathetic} toward it, and possibly one can then anticipate
the agent's behavior. These are central motivations when trying to explain
anthropomorphism, and we will come back to them in more detail later on.
\citet{eddy_attribution_1993} explain that, because of these reasons, people
commonly anthropomorphize their pets, by ascribing mental states, intentions or
feelings to them.\footnote{Interestingly, pet-ownership seems to have a
significant impact on human-robot interaction: several studies suggest that
pet-owners are more likely to anthropomorphize technologies and robots than
non pet-owners} But how can these motivations behind anthropomorphism be
explained from a human-centered point of view?

In the following, we present what we found in reviewing literature that applies
a human-centered perspective on anthropomorphism by building on: \textit{(1)} a
line of research in developmental psychology that studies the attribution of
animacy; \textit{(2)} a line of research in more cognitive sciences that studies
the cognitive processes that underlie anthropomorphism, and \textit{(3)} a
theory that explains anthropomorphism based on psychological factors. 


\subsubsection{Developmental psychology research on the attribution of animacy and intention\\}
\label{sec:developmental-expl}

The phenomenon of attributing animacy and intentions to nonliving objects such
as simple shapes has been intensively studied in developmental psychology. As
mentioned earlier, Piaget found that children tend to ascribe life to the
nonliving. They also tend to interpret physical phenomena in terms of intention
on the part of the non-human subject. For instance children are likely to argue
that \textit{``the sun is hot because it wants to make people warm''}
\citep{leeds_childrens_1992}. In this example it is in fact questionable whether
children really anthropomorphize the sun (believing that it has an intention) or
whether they are using anthropomorphism in a metaphoric sense (because their
conceptions of the world and of the living are not yet fully formed). However,
experiments by \cite{heider_experimental_1944} and
\cite{michotte_perception_1963} showed that also adult participants attribute
animacy and intention to simple things and shapes based on motion. In both
experiments, participants viewed animations of simple shapes, such as circles or
triangles. Asked to describe what they observed, most people developed elaborate
stories, attributing motivations, emotions and relationships between the
objects.\footnote{For more details, the reader may refer to the ``attribution
theory''.}

As mentioned earlier, it seems that there is a natural, relatively spontaneous
reaction that accounts for people's tendency to attribute animacy and intention
to moving shapes, even when there is no similarity of the shape to a human. This
tendency to animize / anthropomorphize is already developed (and even more
distinct) in infants and children. Thus besides the anthropomorphic cues emitted
by the design of the artifact, also developmental stages and people's natural
reaction play a role how far we interpret movements (as one of the
most basic ``life-like'' cues) for instance.


\subsubsection{Cognitive science research, Theory of Mind, and neural correlates
of anthropomorphism\\}

\label{sec:cognitive-expl}

Anthropomorphism and similar phenomenons can also be understood as a thoughtful
process of induction whereby \textit{``people reason about an unknown stimulus
based on a better-known representation of a related
stimulus"}~\citep{epley_when_2008}. In the case of anthropomorphism this means a
person's reasoning about a non-human agent based on the representation of the
self or other humans. A central construct of this perspective is the so-called
\textit{mental model} that a person has (and builds) of the agents he/she is
reasoning about and interacting with. The specific mental model we have about an
artifact / agent basically explains (in our individual way to ourselves) how
this artifact / agent works the way it does.  There are two central aspects
here, that derive from the above quote from Epley.

\textit{(1)} One assumption is that the user is not familiar with the other
agent. This is basically true for all other agents (and entities) but oneself
because we can only be our self. This view is also consistent with the
\emph{familiarity thesis}~\citep{hegel_understanding_2008} which claims that we
understand the world based upon the mental model of the world that we are most
familiar with (\ie our self). Thus, we can best use our self as source of induction
when reasoning about other agents. However, in case we would like to understand
the behavior of a spider, we would probably not use our mental model of a human
(or our self) simply because we do not have many things in common with a spider.
And this is the second central aspect here.

\textit{(2)} One other assumption is based on the anthropomorphic design of the
other agent: if the agent behaves, thus appears, much like a human being (\eg a
robot that emits a human voice), people's mental model of the agent's behavior
is likely to approach their mental model of humans (though the model may differ
in some important aspects).

This cognitive viewpoint on anthropomorphism is important because people's
estimation of an agent's knowledge model and its capabilities affects the way
they relate to it. This holds implications for the resulting interaction with
the system, the user experience, and the acceptance. Previous research examined
the validity of the mental model concept with various kinds of robots
\citep{schmitz_concepts_2011,kiesler_mental_2002}. Findings suggest that people
tend to hold richer mental models of anthropomorphic robots in contrast to
mechanic ones \citep{kiesler_mental_2002}.\footnote{Later in this article,
we may however come to question how far this result is based on
expectations from the human user side, which are likely to be refined
after continued interaction, and after the user gets acquainted with the
robot's behavior.} A similar finding is described in
\cite{hegel_understanding_2008} and \cite{krach_can_2008}. In a user study using
functional magnetic resonance imagery (fMRI), the authors found that
participants implicitly attributed human-like qualities, such as mental states,
to their non-human interaction partner. Indeed, from an early age humans develop
a tendency to explain one's own and others' actions in terms of beliefs, desires
and goals,  called \textit{theory of mind}. The theory of mind allows the
implicit attribution of intentions and other mental states to others
\citep{premack1978does,leslie_pretense_1987,Frith2003}.  The finding of
\cite{hegel_understanding_2008} and \cite{krach_can_2008} was evident at the
behavioral level as well as on the neuro-physiological level: the more the
human-likeness of the artefactual partner increases, the more brain areas
associated with theory of mind  get activated \citep{krach_can_2008}.
Implication of human brain area involved in the inference of others' mental
states has also been shown in response to viewing
non-anthropomorphic/non-humanoid robotic gadgets whose behavior has been
described as unpredictable -- but not in response to those whose behavior was
described as predictable -- a finding also found at the behavioral level
\citep{Waytz2010}.  Interestingly, the grey matter volume of a brain area
related to theory of mind has been correlated to individual's score of
anthropomorphism \citep{cullen2013individual}.

At lower, more automatic, level, robots have been shown to elicit resonance
behaviors in the human brain. Resonance behaviors \citep{Rizzolatti1999} are
mechanisms by which the brain areas involved in the internal representations of
an action, an emotion or a sensation are equally recruited during the perception
of another individual performing the same action or experiencing the same
emotion or sensation.  The neurons showing resonant properties have been called
mirror neurons and have been found in a wide range of modalities (motor,
emotional \etc). Seeing a robotic arm reaching for an object
activates the motor mirror neurons the same way as for seeing a human arm
reaching for the same object \citep{Gazzola2007, oberman_eeg_2007}. However, a
study of emotion perception on a robotic face found reduced activity in
emotional brain area known to have mirror properties in response to the robotic
face compared to a human face \citep{Chaminade2010}. Nevertheless, these authors
showed that when the participants were explicitly instructed to pay attention to
the robot's emotional expression, motor mirror neurons get activated.
Interestingly, using electroencephalography,  it has also been shown that
emotional behavior elicited by a robot face influences the speed of human
responses as well as early brain processes the same way as emotional expression
of a human face did \citep{Dubal2010}.


%


In sum, this branch of research suggests that anthropomorphism implies that
people thoughtfully develop a mental model of agents in their environment and
that they make inferences about these agents based on what is familiar to them
-- themselves, humans and human behavior. This understanding builds on the
theory of mind,  a
person's ability to attribute mental states to oneself and others. 
We briefly reviewed  neuro-physiological evidence of a link between the tendency
to thoughtfully anthropomorphize and the engagement of brain processes involved
in the attribution of mental states to other humans. The human-likeness quality
of the artefactual agent seems to play a role in the involvement of theory of
mind but also the unpredictable feature of the agent behavior alone seems to be
sufficient. Low-level mechanisms of the brain that allow humans to map others'
motor behaviors into their own repertoire are equally elicited when perceiving a
robot's action. It is not yet clear whether humans are processing emotional
signals from a robot the same way as they do for human beings. 


\subsubsection{Social psychology research: a 3-factor theory of anthropomorphism\\}
\label{sec:psychological-factors}

Social psychology, finally, offers theories that apply well to understand
people's motivation to anthropomorphize. Irrespective of the artifact's
characteristics, several psychological determinants have been found to explain a
person's tendency to anthropomorphize. \cite{epley_seeing_2007} present a
\emph{3-factor theory} of when people are likely to anthropomorphize based on
psychological determinants. Namely, the theory suggests that some people are
more likely to anthropomorphize when: 

\begin{enumerate}

    \item ~anthropocentric knowledge is accessible and applicable to the
        artifact (\textit{elicited agent knowledge}),

    \item ~they are motivated to explain and understand the behavior of other
        agents (\textit{effectance motivation}), and

    \item ~they have the desire for social contact and affiliation
        (\textit{social motivation}).

\end{enumerate}

The first factor (\textit{elicited agent knowledge}) is a \emph{cognitive
determinant} of anthropomorphism and based on the idea that a person builds a
mental model (theory of mind) of the other agent. \citet{epley_seeing_2007}
suggest that the process of making inferences about non-human agents is based on
the activation of knowledge about humans (or the self). As mentioned before,
when a person builds a mental model of the other (unfamiliar) agent, the
question here is why does she draw on knowledge about other humans / herself and
not on something else? One basic reasons for this is a person's physical
constraints of being a human and nothing else. Consequently, one has no other
experience than the self and in turn people tend to make inferences about
others' mental states by relying inordinately on their own mental state.
\footnote{Using one's own mental states and characteristics as a guide when
reasoning about other humans is called ego-centrism. In contrast, when using
self-knowledge (or knowledge about humans in general) when reasoning about
non-human agents, this is called anthropomorphism. See
\cite{epley_seeing_2007}.} Also empirical findings suggest that knowledge about
humans in general, or self-knowledge in particular, is likely to serve as a
readily accessible base for induction when reasoning about non-human agents.
This tendency is usually stronger in young children and decreases with cognitive
development and the learning to distinguish the self from other humans, and
non-human agents. 

Both the second factor \textit{effectance} and the third factor
\textit{sociality} are \emph{motivational determinants} of anthropomorphism.
\textit{Effectance} is understood a person's motivation to interact effectively
in one's environment. That means, a person is motivated to be able to
understand, predict, and reduce uncertainty about her environment and the agents
that inhabit it. According to \cite{epley_seeing_2007}, \textit{effectance
motivation} can lead to anthropomorphism, since anthropomorphism serves as one
way to reduce uncertainty and to increase comprehension of events in one's
environment. Again, also according this factor it can be argued that children
are more likely to anthropomorphize than adults. As children are in their early
stages of life, they are likely to feel more uncertain within their environment,
and consequently tend to anthropomorphize more.

The third factor \textit{sociality} describes a person's motivation for social
contact, social connection, and social approval from other agents. In lack of
social connections to other humans (\etc friends, family, colleagues), a person
is more likely to compensate these social connections by anthropomorphizing
non-human agents. In other words \textit{``[...] those who are chronically
lonely should be more likely to anthropomorphize nonhuman agents than those who
are more chronically connected"} \citep{epley_seeing_2007}. Importantly for
anthropomorphism, this social connection often appears to be satisfied by
connections with \textit{``two of the most commonly anthropomorphized non-human
agents, namely pets and religious agents"} \citep{epley_seeing_2007}. Thus, the
motivation of being socially connected increases the tendency to
anthropomorphize non-human agents because first sociality motivation increases
the tendency to perceive human-like characteristics and traits even in non-human
agents, and second it increases the tendency to search for sources of social
connection in one's environment.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%		ANTHROPOMORPHISM AS A MULTI-FACTOR PHENOMENON
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	 



\subsection{Summary: Anthropomorphism as a multi-factor phenomenon}
\label{sec:multi-factors}

Summing it up, anthropomorphism is a commonly discussed and studied trait of
human-robot interaction; however its current understanding seems to be stuck.
More concretely, when seeking to understand why anthropomorphism in an
interaction between a human and a non-human artifact happens, most attention is
given to the artifact and/or to the human. We agree that these two are the
essential ``players'' of anthropomorphism (see Figure \ref{fig:anthropofig}).
Indeed and, as outlined before, research has shown that both the human and the
artifact are not only the two players of anthropomorphism but also the two main
``factors'' that can promote or hinder anthropomorphism.

However, we think that this is not the full story. When agreeing to understand
anthropomorphism as a specific type of \textit{experience} that arises in an
\textit{interaction} between a set of user expectations and the external reality
\citep{persson_anthropomorphism_2000}, 
%(see Figure~\ref{fig:anthropomorphism_and_interaction})
it becomes clear that this interaction happens in a specific context, with a
specific history. We think that the context and the history of the interaction
(in Figure \ref{fig:factors} denoted as \textit{time}), are two more factors
that determine anthropomorphism.

\begin{figure}
    \centering
    \includegraphics[width=0.7\columnwidth]{factors}
    \caption{Anthropomorphism is a multi-factor phenomenon. How far people tend
    to anthropomorphize a robot is determined by four main factors: the design
    of the robot $(R)$, the personal characteristics of the human user $(H)$, the
    situation and context in which the interaction occurs $(C)$, and the amount of
    time (repeated interaction) that the user spends to familiarize herself with the
    robot $(t)$.}

    \label{fig:factors}
\end{figure}

Consequently, we propose a holistic understanding of anthropomorphism as a
phenomenon which is determined by multiple factors (see also Figure
\ref{fig:factors}):

\begin{enumerate}

\item ~the characteristics of the \textbf{robot's design} (degree of
    anthropomorphic form),

\item ~the psychological determinants in the \textbf{human user}
    (see~\cite{epley_seeing_2007}),

\item ~the characteristics of the \textbf{context / situation} in which the
    interaction occurs, and

\item ~the fact of the user getting familiar with the robot \textbf{over time}
    (duration / history of interaction)

\end{enumerate}


When taking into account these multiple factors, a logical consequence seems to
be that anthropomorphism is not either there or not there but that it arises in
different levels, may they be distinct, having multiple layers
\citep{persson_anthropomorphism_2000}. or a continuum being describes in low and
high anthropomorphism \citep{ruijten_introducing_2014}. For instance, 

Moreover, we propose that anthropomorphism shows not only variances determined
by these four main factors but that -- the fourth factor implies this --
anthropomorphism is likely to evolve over time with continued interaction
between the human and the non-human agent.

To facilitate things, we introduce the notation \Ant[R,H,C,t] to bring these
multiple factors together. To take into account dynamics over time, we suggest
that anthropomorphism is a function of a vector of robot's traits $R =
\{r_0,...,r_n\}$, a vector human determinants $H = \{h_0,...,h_n\}$,
characteristics of the interaction context $C = \{c_0,...,c_n\}$, and the
duration / history of the interaction itself, $t$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				PART 2: OUR IDEAS -- A DYNAMIC PHENOMENON
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Anthropomorphism: a dynamic phenomenon}
\label{sec:our-ideas}

So far, the HRI community has not much investigated how anthropomorphism in
human-robot interactions evolves over time (during the process of
\emph{adopting} a robot, for instance). Though conflicts were found in the
understanding of what anthropomorphism is, the HRI community more or less
accepted viewing anthropomorphism as a static feature that once observed during
a short-term interaction reflects a sustaining social effect. However, if we
agree that anthropomorphism arises in an interaction, and thus reflects a
specific relation, we cannot accept it as a static phenomenon.

Similarly, \citet{kanda_interactive_2004} point out that relationships among
people evolve over time and, in a similar manner, one can expect people's
attitude toward technological artifacts and their relationship with them to
evolve as well.  In their study, \citet{kanda_interactive_2004} were among the
first to describe empirically \emph{novelty effects} during a long-term study
with an interactive robot in a school.

From a theoretical perspective, we also expect anthropomorphism to change over
time, with growing experience with a robot. As discussed in the previous
sections, anthropomorphism means in essence \emph{reasoning about and perceiving
    something non-human (and unknown or unfamiliar) based on one's
representation of the familiar and well-known concept of being human (or
one-self)}. According to \citet{epley_when_2008}, the basic operations that
underlie these inductive inferences are the \emph{acquisition of knowledge}, the
\emph{activation or elicitation of knowledge}, and the \emph{application of
activated knowledge at the time of the judgment}. By applying knowledge to a
given situation or interaction, one also attempts to correct, adjust, or maybe
integrate less accessible information into a more automatically activated
default representation.  This process of refining the applied knowledge are
natural because a person's knowledge base changes constantly with newly acquired
things. For instance, a person can acquire new knowledge about a robot when
interacting with it. With continued interaction with the unknown system also the
user's expertise with the system grows, and it can be expected that in turn, the
user will become able to better predict the previously unknown system.
Consequently, as the robot becomes more predictable, there is less uncertainty,
and the ``need to anthropomorphize'' the robot decreases (from the
human-centered point of view).

In other words, humans have a motivation to interact effectively in their
environment \textit{(effectance)} \citep{epley_when_2008}.  This means that
humans are motivated to be able to understand and predict the environment and
the agents around them. Thus, a person will seek to become familiar with what is
unfamiliar. Anthropomorphism is encouraged when an agent is unfamiliar.
Consequently, in the process of familiarizing oneself with an agent, the
tendency to anthropomorphize this agent should decrease.

We can not be sure about how exactly the process of familiarization to an
unfamiliar agent (based on continued interaction with the robot) looks like. In
turn, we can not make a precise statement about how continued interaction
decreases anthropomorphism but we suspect there is a link between the two.

In the introduction, we reported on a few selected experimental results that
illustrate how the user tendency to anthropomorphize decreased over time.
Combined with the extensive discussion on the nature and factors of
anthropomorphism that we proposed in section~\ref{sec:anthropomorphism}, we
introduce in the following section a novel qualitative model of the evolution of
anthropomorphism over time, \ie a model of the \emph{dynamics of
anthropomorphism}.


\subsection{A Model of the Dynamics of Anthropomorphism}
\label{sec:dynamics-model}

The phenomenological model of anthropomorphism we propose
(Figure~\ref{fig:dynamics},~\citep{lemaignan2014dynamics}) represents how the
level of ``anthropomorphic effects''~\Ant[R,H,C,t] (\ie the observable
manifestations of anthropomorphism) evolves over a long-term human-robot
interaction.\footnote{We cannot make a precise statement about how long
``long-term'' interaction has to be to be considered as such. It seems to be
practical to not speak of ``several days'' or ``weeks'' but to rather consider
the duration and frequency of the actual interactions with the artifact. One
could probably call this the ``interaction history''.}

While the model primarily considers \emph{long-term interaction} -- direct
(non-mediated), repeated interaction with the same robot, over an extended
period of time (typically longer than a week), we also formally introduce a
so-called \emph{novelty effect}~\citep{kanda_interactive_2004} that models the
first phase of human-robot interaction, during which a specific increase of
anthropomorphic interactions is observed.

In the \emph{Dynamics of Anthropomorphism} model, anthropomorphism is quantified
by a \emph{normalized level of anthropomorphic effects} $\antNorm[R,H,C,t] =
\frac{\ant[R,H,C,t]}{\antMax}$: because anthropomorphic effects are often
qualitative and difficult to quantify on an absolute scale, we present them as a
normalized value, that spans from a minimum (no anthropomorphic effects:
$\ant=0$) to a maximum (noted \AntMax, with $t_{max} = \operatorname{arg\,max}_t
\, \ant[t]$). For the sake of readability, we will use \Ant in the following
sections to refer to the normalized level of anthropomorphic effects. Note also
that we discuss in Section~\ref{sec:measuring} possible methodologies for the
quantitative and qualitative assessment of anthropomorphic effects.

The actual maximum value of anthropomorphic effects depends on each unique
combination of a human, a robot, a situation and several other factors we
introduce below. Thus, the maximum value varies according to the specific
characteristics of these factors. Figure~\ref{fig:dynamics} pictures this
maximum value at $t_{max}$, which actually corresponds to what we call the
novelty effect peak.\footnote{We assume that there is a peak in the human's
experiences of the novelty effects of the unfamiliar system. Further, we suspect
that this novelty peak comes along with the maximum value of anthropomorphic
effects.} The general \emph{shape} of the curve remains however the same and
depicts the evolution of anthropomorphism over time, \ie the general dynamics of
anthropomorphism.

\begin{figure*}[htb]
\centering


\begin{tikzpicture}[scale=1.4]

% background shading
\path[fill=green!20] (0,0) rectangle (0.6,5.5);
\path[fill=blue!15] (0.6,0) rectangle (5.2,5.5);
\path[fill=orange!20] (5.2,0) rectangle (9.8,5.5);
\draw(0,5.5) node[anchor=south west, rotate=10] {\scriptsize \sc Initialization};
\draw(2.5,5.5) node[anchor=south west, rotate=10] {\scriptsize \sc Familiarization};
\draw(6.5,5.5) node[anchor=south west, rotate=10] {\scriptsize \sc Stabilization};
% horizontal axis
\draw[->] (0,0) -- (10,0) node[anchor=north] {$t$};
\draw(5,-0.1) node[anchor=north] {\scriptsize Duration of interaction};


% vertical axis
\draw[->] (0,0) -- (0,6) node[anchor=east] {};
\draw(-0.8,3) node[rotate=90,anchor=south] {\scriptsize Anthropomorphic effects};

\draw (-0.05, 3) -- (0.05, 3) node[anchor=east] {\ICA};
\draw (-0.05, 5) -- (0.05, 5) node[anchor=east] {\AntMax};

% vertical axis - end
\draw[->] (9.8,0) -- (9.8,2) node[anchor=east] {};
\draw (9.8, 0.8) node[anchor=west] {\SLA};


\draw[<-] (0.65,5) -- (0.8,5.2) node[anchor=east] {};
\draw (0.9,5.3) node[anchor=west] {\tiny \it novelty peak};

\draw[dashed] (0.6, 0) -- (0.6,5.1);
\draw (0.6,0) node[anchor=north] {$t_{max}$};

\draw[dotted] (0, 5) -- (6.2,5);
\draw[dotted] (0, 3) -- (6.2,3);
\draw[<->] (6.1,3) -- (6.1,5) node[sloped, above, midway] {$\Delta_{a}$};

\draw[<-] (1.7,4.4) -- (3.2,4.1) node[anchor=east] {};
\draw[<-] (2.85,2.6) -- (3.2,4.1) node[anchor=east] {};
\draw (3.2,4.1) node[anchor=west, align=center] {\tiny \it disruptive\\ \tiny
\it behaviors};
%%%%%
%% CURVES
%%%%
\begin{scope}[yscale=-1,shift={(-0.125,-0.4)}]

    \draw[ultra thick] svg[scale=1cm] "M 0.125,-2.5619582 c 0.0200733,-1.1573591
    0.33954391,-1.9982333 0.57940683,-2.0013597 0.13691605,0 0.25550329,0.052908
    0.37497897,0.1661788 0.119476,0.1130305 0.2396954,0.2786079
    0.37944,0.4790565 0.069872,0.099803 0.1021612,-0.2231749
    0.1792538,-0.2238964 0.099707,0 0.013454,0.4985362 0.3173383,0.9139831
    0.1911917,0.2612926 0.3444354,0.2578391 0.6711932,0.4894291
    0.2058265,0.1458798 0.1571532,0.9762306 0.2615031,0.9702183 0.097182,0
    0.083295,-0.3336208 0.4330446,-0.1199242 0.4306401,0.2631203
    0.216699,0.1355642 0.4296663,0.2647074 2.0858202,1.13836043
    4.34683,1.41300027 6.3741749,1.43753027";

    \draw[dashed] svg[scale=1cm] "M 0.125,-0.1952939 c 0.0553601,-3.1917862
    0.33954391,-4.3648976 0.57940683,-4.368024 0.13691605,0 0.25550329,0.052908
    0.37497897,0.1661788 m 2.6714393,2.7735737 C 4.7653984,-0.85050947
    6.5955093,0.35382293 10.125,0.4062498";

    \draw[dashed] svg[scale=1cm] "M 0.125,-3.6923825 C 0.1102888,-4.0297903
    0.46454391,-4.5601915 0.70440683,-4.5633179 M 3.7508251,-1.6235654 C
    4.9579368,-0.95548345 8.1358175,-0.82609971 10.125,-0.79459549";



\end{scope}

\end{tikzpicture}

\caption{The dynamics of anthropomorphism. We distinguish three main phases:
    \emph{initialization}, \emph{familiarization} and \emph{stabilization},
    preceded by a \emph{pre-interaction} phase. The pre-interaction phase
    is characterized through an \emph{initial capital of anthropomorphism} (ICA, noted \ICA).
    Once the interaction starts, the level of anthropomorphism increases due to
    the \emph{novelty effect}, and then decreases to reach a \emph{stabilized
    level of anthropomorphism} (SLA, noted \SLA). \ICA and \SLA may vary
    depending on the user (and his/her expectations), the robot and the context
    of interaction.  During the interaction, unpredicted behaviors of the robot
    (\emph{disruptive behaviors}) may lead to local increases or decreases of
    the level of anthropomorphic effects.}

\label{fig:dynamics}
\end{figure*}

\subsection{Three phases}
\label{sec:phases}

We distinguish three main phases that describe the evolution of the
anthropomorphic effects in a long-term human-robot interaction. They are
depicted in different shades in Figure~\ref{fig:dynamics}.

First, the \emph{initialization} phase. During this short phase (from a couple
of seconds to a couple of hours), we observe an increased level of
anthropomorphism, from an \emph{initial capital of anthropomorphism} \ICA
(detailed in the next section) to a peak of anthropomorphic manifestations
\AntMax that corresponds to the maximum of the \emph{novelty effect}.
Section~\ref{sec:initialization} details this first phase.

The second phase, \emph{familiarization}, lasts longer (up to several days) and
models the process of the human getting acquainted to the robot: by observation
and interaction, the human builds a model of the robot's behavior that allows
him/her to predict the robot's actions. We observe a decrease of
anthropomorphic effects during this phase, that we explain by the acquired
ability to predict the behavior of the robot: the initial apparent behavioral
complexity vanishes, and the robot is considered more and more as a tool.
Section~\ref{sec:familiarization} discusses the second phase.

The last phase is the \emph{stabilization} phase. The level of anthropomorphic
effects tends to stabilize over a longer time, to reach a \emph{stabilized
level of anthropomorphism} \SLA. \SLA may be null (no anthropomorphic
effects observed anymore), but it may also remain at a higher level.  This
third phase, as well as the \emph{stabilized level of anthropomorphism}, are
discussed in section~\ref{sec:stabilization}.


\paragraph{Pre-interaction phase and Initial Capital of Anthropomorphism (ICA)\\}
\label{sec:ica}

The \emph{initial capital of anthropomorphism} \ICA describes the initial
potential for the robot to be anthropomorphized by the human user in a given
situation.  This potential depends on several factors, introduced in
section~\ref{sec:multi-factors}, see also Figure \ref{fig:factors}. It has been
shown, for instance, that some \textit{people} tend to anthropomorphize more
than others, that some \textit{situations} induce anthropomorphism more than
others, that \textit{children} tend to anthropomorphize more than adults, and
that some \textit{cultures} are notorious for their anthropomorphic religions
and worldviews~\citep{epley_when_2008}. Also the shape and design of the robot
play a role, as well as the context in which the interaction takes place. Our
model of anthropomorphism represents these factors as a compound metric \ICA. As
such, \ICA describes the level of anthropomorphic projections just prior the
first (real or imagined) interaction with a robot. In this stage of
pre-interaction, people form \textbf{initial expectations} toward the robot and
imagine how they will use it / interact with it.

Taking up on our suggestion to have four main factors that impact on
anthropomorphism, we propose that the initial capital of anthropomorphism can be
build \emph{a priori}.  As the \ICA marks the very moment before the first real
or imagined contact of the human with the robot, the \textit{interaction
history} between the two players is empty; consequently the time factor $t$ is
not taken into account when building the \ICA.  The specific \ICA value reflects
how far a robot is likely to be anthropomorphized, based on the following three
factors:

\begin{enumerate}

    \item ~\emph{Human factor} $S$: The \textbf{personality} and individual
        traits of the human user: Psychological characteristics / determinants
        that influence a person's tendency to anthropomorphize
        artifacts~\citep{epley_seeing_2007}. Other individual traits and
        demographic aspects are comprised (\eg age, gender, cultural background,
        professional background).

    \item ~\emph{Robot factor} $R$: The robot's \textbf{design} and how it
        appears to the human user. Characteristics of the robot's form,
        behavior, and interaction modalities (anthropomorphic
        design)~\citep{fong_survey_2003}.

    \item ~\emph{Context factor} $C$: The real or imagined
        \textbf{purpose} of the robot, including the situational context in
        which it is used, as well as the task context and role in which the
        robot is used / experienced (environmental
        context)~\citep{joosse_what_2013}.

\end{enumerate}	


For \textbf{personality}, we suggest to apply the psychological \textit{3-factor
theory} of anthropomorphism by \citet{epley_seeing_2007}. For instance, children
generally tend to anthropomorphize objects more than adults. Also, a person who
lacks social connection is said to be more likely to anthropomorphize. Both
aspects would increase \ICA. This means that, one and the same robot used by a
different user, can lead to a different \ICA.

For \textbf{design}, we understand that a robot that follows an anthropomorphic
design up to a certain acceptable level (\eg Nao) leads to a higher \ICA than a
rather functional robot (\eg Roomba). Also, a robot that is able to display
facial expressions would increase the \ICA. Quantifying the \emph{level} of
anthropomorphic design in a robot, as suggested for instance by
\citet{fong_survey_2003}, can be difficult.  Nevertheless, the important aspect
is how the robot appears to the user, \eg human-like or machine-like, acceptable
or not-acceptable.\footnote{It becomes clear that the \textit{robot factor} can
not be fully separated from the \textit{human factor}. The reason for this is
that the message that design tries to make, always lies in the eye of the
beholder. No matter how much effort a designer spends in making the ``message''
of the artifact's design clear, there is always some scope and creative freedom
in how the design is interpreted by the beholder.}

By taking the \textbf{purpose} of a robot into account, we suggest that the real
or imagined application context of the robot, or in which situation the
interaction occurs, impacts how far the robot will be attributed human-like
characteristics. We draw on findings such as presented in
\citet{joosse_what_2013}. The authors showed for instance that when the same
robot (Nao) is used in a different task context (cleaning task \emph{vs.} tour
guide), users ascribe different personalities to the robot. In general, a robot
which is imagined in a social, entertaining or playful context leads to a higher
\ICA than a robot which is used for a routine or focused task (security, rescue,
etc.). This was also found in an analysis of anthropomorphic language in online
forum discussions about the AIBO, Roomba, and iPad
\citep{fink_anthropomorphic_2012}. Regardless of the conversation topic, more
anthropomorphic language was found in the AIBO forum. However, this was not only
due to the zoomorphic (pet-like) shape of AIBO but also due to its  playful
purpose. The idea that the purpose of a robot are crucial factors, also receives
support from Goetz \& Kiesler's work that revealed that people prefer a serious
robot for serious tasks and a less serious robot for more playful
tasks~\citep{goetz_cooperation_2002, goetz_matching_2003}.  However, what about
artificial agents that seem to have no purpose? \cite{kaplan_free_2000}
discusses the role of uselessness in the design of robots. He argues that
artificial pets such as the AIBO, have no real purpose, in a sense that they do
not provide any kind of service, or, in other words \textit{``they are not doing
what you tell them to do''} and \textit{``they might refuse the order of its
owner''}. It is this very aspect that might increase people's tendency to
anthropomorphize the robot. According to Kaplan, it is in our daily use
language, that we tend to attribute intentions to devices that are not doing
their job well. For instance, we do not develop any kind of relationship with
our computer, washing machine or TV set when they work properly. The author
argues that it is only when they start dis-functioning, when they show that they
can act differently that what we ordered, that we are ready to give them some
kind of ``intentionality''.

Also, we suggest that the environmental context in which people experience and
interact with the robot impacts the \ICA. For instance, several friends
interacting simultaneously with the robot might lead to increased \ICA for each
of the users, due to increased human-human social interactions (the robot might
be perceived to be part of the social interaction, and in turn attributed
human-like qualities~\citep{baxter2013do}).


\subsubsection{Initialization Phase\\}
\label{sec:initialization}

%\paragraph{The Novelty Effect\\}
%\label{sec:noveltyeffect}

We assume that the short phase of initialization is strongly affected by the
so-called novelty effect.  Novelty effects have been described with interactive
technologies in general \citep{rogers_diffusion_1995} and also in several
long-term HRI studies in workplaces
\citep{huttenrauch_fetch-and-carry_2003,mutlu_robots_2008}, in schools and
public places
\citep{gockley_designing_2005,kanda_interactive_2004,kanda_communication_2005},
or elder care centers \citep{sabelli_conversational_2011}. Further, also with
domestic robots it has been found that people's interest, engagement, and
fascination with the robot decreased over time
\citep{fink_living_2013,fernaeus_how_2010,sung_robots_2009}.

To illustrate how the novelty of a robot can evoke anthropomorphic effects, we
present an example from our long-term ethnographic study with Roomba vacuum
cleaning robots in households \citep{fink_living_2013}. The observed scenario
describes how an elderly woman (E., 71 years, living on her own with a little
dog in a small row house) was setting up and using the robot for the first time
during about 10 minutes.

At several occasions, while watching how the robot moves around and cleans, E.
makes compliments to the robot: \emph{``Nice!''} or \emph{``Good job!''} or
\emph{``Bravo!''}. Once, when the Roomba turns right in front of some crumbs on
the kitchen floor and moves away without cleaning them up, E. says:
\emph{``There you forgot something, what about over there? Look, there you still
have something to clean up!''}, and she points at where she wants the Roomba to
go. Further, she uses deictic gestures and tells the robot: \emph{``No, go this
way! Come over here!''}. The woman keeps observing the robot and wonders about
its intentions, asking it directly: \emph{``Why do you leave the kitchen? There
is still something there on the fringe!''}. E. turns to the experimenter, and
tells her: \emph{``She [the robot] loves the hall!''}.

Besides this behavior of generally anthropomorphizing the robot, we observe the
following concrete instances as anthropomorphic effects in this scenario:
talking directly to the robot, or asking it questions (though it doesn't
recognize speech); giving it nick-names or ascribing a gender, praising the
robot, using pointing gestures toward the robot, or trying to direct it around
with commands, and attributing a personal preference / intention to the robot
(\emph{``she loves the hall!''}).

During the following visits at the woman's place, E. did not talk to the robot
anymore, and generally behaved in a less anthropomorphizing way. The observed
effects were likely due to the novelty of the robot, and the fact that E. was
not familiar with the robot and its behavior.  As
\cite{persson_anthropomorphism_2000} names it: \textit{``Anthropomorphism is a
way of making sense of complex behavior in the world around us.''} Thus, as soon
as this complexity is reduced, also anthropomorphism might be reduced.
 

\subsubsection{Familiarization Phase\\}
\label{sec:familiarization}

In this context, \emph{familiarization} means \emph{to get acquainted with}.
It is not to be confused with the \emph{familiarity thesis} that relates to the
projection of already known cognitive models onto the robot. We discuss this other
aspect in section~\ref{sec:cognition-neuroscience}.

The \emph{familiarization phase} starts at the peak of the \emph{novelty
effect}: anthropomorphic effects are at their maximum, the user thinks (s)he is
potentially facing an agent aiming at ``human-level intelligence'' (to take
McCarthy's words). This is a transient state that quickly vanishes, and the
projected anthropomorphism then starts to decrease while the human observes and
recognizes that the behavior of the robot is generally \emph{predictable} and
possibly \emph{deceptive} (for instance, it talks but does not understand when
we talk; it has eyes but does not recognize everyday objects we show; \etc).

\paragraph{Disruptive behaviors\\}

By \emph{disruptive behaviors}, we mean any behavior exhibited by the robot that
appears unexpected to the user: for instance, a robot may usually follow always
the same route to go from one place in a house to the other, but suddenly it
might change the route. The actual underlying reason may span from a bug to the
detection of a new obstacle, but as long as this reason is not immediately
intelligible to the user, the behavior counts as \emph{disruptive}. (We will
come back to the role of disruptive behaviors later, in Section
\ref{sec:disruptive}.)

As illustrated in Figure~\ref{fig:dynamics}, our model represents
\emph{disruptive behaviors} as either local increases or local decreases of
anthropomorphic effects in the familiarization phase (and at a lesser extend, in
the stabilization phase): because such behaviors are unexpected, a human
observer may interpret them either as the result of a richer deliberative
process, which in turn leads to the supposition of complex cognitive skills, or
conversely as a failure, reminding the human that the robot is ``just a
machine''. Section~\ref{sec:disruptive} discusses more in depth the impact of
the user's perception of disruptive behaviors, and their cognitive correlates.

To illustrate how a disruptive behavior of a robot can evoke anthropomorphic
effects, we present again an example from our long-term ethnographic study with
Roomba vacuum cleaning robots in households \citep{fink_living_2013}. The
observed scenario describes how a family (young parents, 26 and 28 years old,
with 3 little children, 5 and 4 years, and 6 months old, living in a house with
garden on the countryside) were using the robot during the first week.

The father (M.) always lets Roomba clean up the ground floor after the family
finishes dinner and they all go upstairs to put the children to bed. When the
robot would have finished its cleaning cycle, the parents would later just find
it docked at its charging station. It used to be like this every evening.
However, one day when the father comes downstairs, Roomba is not at its station.
He says: \emph{``Hey, Roomba, where are you? Why did you not want to got to
sleep last night?''}. After some searching he found it stuck under the sofa and
wondered why this had happened. 

What is the observed anthropomorphic effect in this scenario? Usually, the
father did not talk to the robot or praise it. However, now that the robot did
something unexpected (it was not at its usual place) he started wondering about
its ``intention'' and directly asked the robot for its reasons to not
\textit{``go to sleep''}. 


\subsubsection{Stabilization Phase\\}
\label{sec:stabilization}

The last phase is the \emph{stabilization} phase. The level of anthropomorphic
effects tends to stabilize over a longer time, to reach a \emph{stabilized
level of anthropomorphism}, noted \SLA.

If, after the familiarization phase, no anthropomorphic effects are observed
anymore, $\sla = 0$. This can be interpreted as the user interacting with the
robot in a routine way, without projecting anymore human-like traits on the
robot.


\paragraph{Stabilized Level of Anthropomorphism\\}

The \emph{Stabilized Level of Anthropomorphism} describes the long-term lasting
level of anthropomorphism.  We proposed that \ICA is built on three factors:
user's \emph{personality}, robot's \emph{design} and interaction \emph{purpose}
(or \emph{interaction context}). The user's personality and the context of use
do also influence \SLA.  In particular, it appears that the user's level of
acquaintance with technologies plays an important role in long-term tendency to
anthropomorphize~\citep{fink_living_2013} (people more familiar with technology
understand, and hence predict, better the behavior of the robot, which in turn
leads them more frequently to ultimately consider the robot as a simple tool).

The robot's design, on the other hand, plays a more subtle role, and strong
initial anthropomorphic design does not mandate high \SLA: lasting
anthropomorphic effects have been observed on non-anthropomorphic robots (like
the iRobot Roomba~\citep{fink_living_2013} or the military iRobot
PackBot\footnote{Rodney Brooks has reported in keynotes that occasionally
soldiers would give a name to \emph{their} PackBot and require it to be repaired
instead of being replaced by another one in case of incident.}), and on the
contrary, anthropomorphic designs can lead to higher expectation deceptions,
resulting in the robot not being used anymore.

Note that the \emph{Initial Capital of Anthropomorphism} and the
\emph{Stabilized Level of Anthropomorphism} are generally not correlated: one
individual may have high potential of anthropomorphizing (high \ICA) at first
sight of a good-looking humanoid robot, and get disappointed by the actual
abilities of the robots, down to routine, non-anthropomorphic, interactions (low
\SLA), while another user with the same high \ICA may, for instance, creates
lasting affective bonds with the same robot, and keeps anthropomorphizing it
(higher \SLA).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%		PART 3: EXPLANATIONS -- COGNITIVE CORRELATES, NEUROSCIENCE VIEW
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Cognitive Correlates of Anthropomorphism}
\label{sec:cognition-neuroscience}

This section provides an initial interpretation of anthropomorphism in
terms of \emph{cognitive correlates}: how human cognition can explain the
dynamic nature of our interactions with robots, and what are the main cognitive
stages upon which researchers can build to design better, deeper human-robot
interactions.

The next sections introduce a model of the cognitive stages involved in
human-robot interaction, that can be interpreted in parallel to the model of the
dynamics of anthropomorphism.

We also discuss two specific aspects: the cognitive impact of disruptive
behaviors (section~\ref{sec:disruptive}) on mutual modeling, and how our models
relate to the \emph{in-the-moment} versus \emph{reflective} perspectives on
agency in HRI~\citep{takayama_perspectives_2012}.


\subsection{A Model of the Cognitive Stages of Human-Robot Interaction}
\label{sec:cognitive-model}


\begin{figure}[htb]
\centering
%\resizebox{\linewidth}{!}{
\begin{tikzpicture}
\baselineskip=8pt

\path[fill=gray!20] (0,0) rectangle (10.5,2);
\path[fill=gray!50] (0,2) rectangle (10.5,4);
\path[fill=gray!20] (0,4) rectangle (10.5,6);

\draw (-0.3,1) node[rotate=90] {Stage 1}
      (-0.3,3) node[rotate=90] {Stage 2}
      (-0.3,5) node[rotate=90] {Stage 3};

\draw[->] (0,0) -- (11,0) node[anchor=north] {$t$};
\draw[-|] (0,0) -- (0,6.5) node[anchor=east] {};
% Us
\draw[ultra thick, ->] (0,0) -- (1,2) -- (3,2) -- (4,4) -- (6,4) -- (7,6) --
(9.5,6);
\draw[ultra thick, dashed, ->] (3,2) -- (9.5,2);
\draw[ultra thick, dashed, ->] (6,4) -- (9.5,4);

\draw (11,1) node[align=left, anchor=west]{\scriptsize pre-cognitive\\\scriptsize anthropomorphism}; %label

\draw (11,3) node[align=left, anchor=west] {\scriptsize{projection of existing}\\\scriptsize{mental models}\\\scriptsize{\it (familiarity)}}; %label

\draw (11,5) node[align=left, anchor=west] {\scriptsize{adapted mental
model} \\ $\to$ \scriptsize{adapted interaction}\\\scriptsize{\it (anthropomorphic or not)}}; %label


\draw[dashed,->] (1,0.1) to[bend right] (2,1.9)  node at (4.5,1) {\tiny{\it observation (shape, motion, sound)}}; %label

\draw[dashed,->] (4,2.1) to[bend right] (5,3.9)  node[align=left] at (7.5,3) {\tiny \it observation (interactive behavior) \\ \tiny \it or short interaction}; %label

\draw[dashed,->] (7,4.1) to[bend right] (8,5.9)  node[align=left] at (9,5)
{\tiny \it contextualized\\ \tiny \it interaction}; %label

\end{tikzpicture}
%}
\caption{The three cognitive stages of anthropomorphism: Stage 1 is the instinctive,
sub-cognitive identification of living peers. {\it Empathy} is characteristic
of this stage. After longer observation or short, non-contextualized interaction
(typically, a lab environment), the user reaches Stage 2: the user projects a
mental model he/she is already familiar with onto the robot. After longer {\it
contextualized} interaction (typically, at home), the user enters Stage 3 of
anthropomorphism: the user composes a custom mental model of the robot,
based on experience. This leads to adapted interaction modalities, that may
still be anthropomorphic, or not.}
\label{fig:cognitivemodel}
\end{figure}

We propose three different cognitive stages (Figure~\ref{fig:cognitivemodel}),
which are not mutually exclusive but overlap over time. Note that these three
cognitive stages are related but do not exactly match the \emph{Initialization},
\emph{Familiarization} and \emph{Stabilization} phases introduced in our model
of the dynamics of anthropomorphism.


\subsubsection{Cognitive Processes and Stages\\}

The main underlying cognitive process in anthropomorphism is understood as
perceiving and reasoning about something non-human and unfamiliar based on one's
representation of the familiar and well-known concept of being
human~\citep{epley_when_2008}. This led us to interpret the phases of
anthropomorphic interactions as parallel cognitive phases
(Figure~\ref{fig:cognitivemodel}).

The \emph{Stage 1} is the instinctive, pre-cognitive identification of living
peers. Studies conducted by~\citet{rosenthal-vonderputten_experimental_2013},
who investigated the neural correlates of emotional reactions of humans towards
a robot, supports the idea that humans tend to anthropomorphize robots
intuitively in this pre-cognitive way. {\it Empathy} is characteristic of this
stage~\citep{rosenthalvonderPutten2013neural}.  It is also at this stage that
automatic activation of the human's mirror neurons system  in response to
viewing the robots action and human automatic emotional responses are
contributing at a lower level to the intuitive anthropomorphization.

The intuitive anthropomorphization in the cognitive Stage 1 might be
characteristic of what \cite{takayama_perspectives_2012} calls the
\textit{in-the-moment} perspective on agency with a robot compared to the
\textit{reflective} perspective (see paragraph ``artifact-centered perspective''
in Section \ref{sec:anthropomorphism}).  For instance, we reflectively might
\textit{not} perceive agency in a social robot, but it can feel quite
differently in the moment of interaction. \cite{takayama_perspectives_2012}
argues that neglecting to separate reflective perspectives from in-the-moment
perspectives of agency is one of the major sources of confusion when people talk
and write about anthropomorphism. There seems to be a disconnection between what
people consciously perceive and how they respond to stimuli that they may not
consciously perceive. That means, in the initial phase of interacting with a
novel device \textit{(initialization)} (see Figure \ref{fig:dynamics}) people
might not respond consciously but rather mindlessly \citep{nass_machines_2000},
and in turn anthropomorphize more.  Only after some time of
\textit{familiarization}, they might respond in a more reflective manner (in
turn, the tendency to anthropomorphize might decrease). This can be illustrated
by the fact that people tend to deny interacting with computational systems as
if they were people and yet they respond to computers in many ways that are
remarkably similar to how they respond to people \citep{reeves_media_1996}.
\cite{takayama_perspectives_2012} also applies a cognitive viewpoint on the two
different perspectives of in-the-moment \vs reflective to illustrate
differences. She states that in-the-moment perceptions of agency are largely
shaped by bottom-up perceptual processes, evoking very immediate responses (\eg
to the cues emitted by the artifact's design (``artifact-centered
perspective''). In contrast, according to Takayama, reflective perceptions are
more often shaped by top-down processes because of the nature of reflective
thought.

After a longer observation period (typically including complete action sequences
of the robot) or short interaction (touching, short talk like greetings), we
suggest the human reaches the cognitive \emph{Stage 2}: in this phase, the human
starts building a behavioral and cognitive model of the robot that would support
both the observed and imagined capabilities of the robot.  The \emph{familiarity
thesis}~\cite{hegel_understanding_2008} supports the idea that the human first
projects onto the robot mental models of similar agents he/she is already
familiar with (ranging from animals to human adults, to pets and children). We
hypothesize that the nature of the projected mental model, as well as how deep
the human engages in this projection, might be driven by the same parameters as
we mentioned for the \emph{initial capital of anthropomorphism}
(section~\ref{sec:ica}).  At this stage the human might also change his attitude
towards the robot, paying more attention to social cue than to low-level
behavior which may reinforce the resonance mechanisms. 

The cognitive \emph{Stage 3} is reached after a \emph{contextualized} interaction.
A \emph{contextualized} interaction is \emph{explicitly purposeful} (the purpose
of the interaction, be it purely entertainment, is explicit and conscious to the
human), and takes place in an environment that fosters a stronger cognitive (and
possibly affective/social) commitment from the human in the interaction
(typically, at home). During this interaction, the human iteratively restates
and reshapes his/her behavioral and mental model of the robot (\emph{How does
the robot react to such and such situation/input?  What does the robot know
about me? About itself? About our environment? What can the robot learn?}, etc.).

This mental process depends on the human understanding of the robot's inner
working, as well as his/her own tendency to anthropomorphize (the
\emph{personality} in ICA factor), but at this stage, the \emph{perception} of
the robot (its shape for instance) and its intended \emph{purpose} play a less
important role. It is mostly a human-centric process.  The result of this third
phase would be an iteratively adapted cognitive model of the robot. It is also
at this last stage that the human might have a modified tendency to
anthropomorphize, because he/she has built a full cognitive model of the robot.
Consequently, the human would now be able to attribute appropriate internal
states to the robot through his/her theory of mind.


\paragraph{Relation to the dynamics of anthropomorphism\\}

As mentioned before, the three cognitive stages proposed here do not match with
the three phases in the \emph{Dynamics of Anthropomorphism}.  In particular, the
cognitive Stages 1 and 2 are both included in the \emph{initialization} phase of
the anthropomorphism model. Sub-cognitive anthropomorphism typically
\emph{initiates} the novelty effect by rapidly engaging the human in the
interaction through an initial projected agency, whereas cognitive Stage 2
(projection of familiar mental models) supports the novelty effect by inducing
beliefs that the robot is set up with possibly complex cognitive abilities.

The cognitive Stage 3 also overlaps with the \emph{Familiarization} phase: as
the human gets used to the robot, he/she restates and adapts its
cognitive model of the robot by iteratively reshaping pre-existent, familiar
models until it provides a satisfying support to explain and justify the
observed robot behavior.

A \emph{stable level of anthropomorphism} is reached when the adaptation process
depicted in the cognitive Stage 3 reached a stable state, \ie the user's
experience with the robot is correctly supported by the cognitive model he/she
has built.

Another way to think of the three proposed cognitive stages is to relate them to
the \textbf{user experience} which is characteristic of these three stages. For
instance, \cite{norman_emotional_2003} characterizes  three user experience
dimensions (related to emotional attachment), which occur when people use or see
a product for the first time: \emph{(1)} the \emph{visceral level}, which is the
first impression of a product based on its experience; at this level people do
not think about a product but make spontaneous judgments; \emph{(2)} the
\emph{behavioral level}, in which people use and experience the product,
appraise its functions, and consider aspects such as usefulness and usability;
\emph{(3)} the \emph{reflective level}, in which consciousness takes part in the
process, and past experiences are taken into account.  In a study which was
carried out in a shopping mall, \cite{weiss_i_2009} explored the emotional
attachment during first time reactions of children and adults with the robotic
dog AIBO. The authors also argue that it is important to understand the
long-term development of people's social bonds to robots.


\subsection{Role of disruptive behaviors}
\label{sec:disruptive}

A cognitive interpretation of anthropomorphism also allows to better interpret
the role of unexpected robot behaviors, that are \emph{disruptive} with respect
to the cognitive process of building a mental model of the robot.

Common observation of naive people (children or adults) interacting with robots
shows that unexpected behaviors of the robot can have a notable impact on
interaction. This is supported by the results from~\citet{Waytz2010}, mentioned
in section \ref{sec:cognitive-expl}, that show that people attribute more easily
anthropomorphic features to artifacts when they have unpredictable behaviors.
Also \cite{short_no_2010} found that variations in a robot's behavior (such that
it is unexpected) influence people's attribution of mental states and
intentionality to a robot. Participants who were playing the
``rock-paper-scissors'' game with a robot that tried to cheat (either verbally
or in its action), displayed a greater level of social engagement and made
greater attributions of mental states.  However, an unexpected (disruptive)
robot behavior might also have a negative effect on user's engagement with the
robot. For instance, when the user interprets the robot's behavior as a failure,
he/she might lose trust in the robot. \cite{desai_impact_2013} found that in an
interaction scenario, especially early failures of the robot can cause a
dramatically lower real-time trust, compared to middle or late drops of
reliability of the robot.

During a normal interaction with the robot, the user iteratively refines his/her
own model of the behavior of the robot. As explained in previous sections, as
the user improves his/her model of the robot's actions, he/she also improves the
ability to predict the actions and thus, the user tends to anthropomorphize
less.

We emit the hypothesis that an unexpected robot behavior might lead the user to
suddenly restate his/her behavioral model of the robot and will temporarily lead
to an increase or decrease of the level of anthropomorphism (depicted by the
spikes in Figure~\ref{fig:dynamics}).

\begin{figure}
    \centering
    \includegraphics[width=0.75\columnwidth]{un-expected-behavior.pdf}
    \caption{Behaviors of the robot that are unexpected by the user may be intentional
    (the robot has planned the behavior) or not (typically, a failure:
    misdetection, bug,...). Independently of that, the behavior may be
    \emph{perceived} by the user as intentional or not.}

    \label{fig:perceptionUnexpectedBehavior}
\end{figure}


When talking about \emph{unexpected robot behaviors}, several distinct cases
must however be considered, summarized in
Table~\ref{fig:perceptionUnexpectedBehavior}.

If the unexpected behavior is not planned, and perceived as such by the human
(case I), the human can interpret that the robot is able to fail. If the robot
explicitly states its failure (for instance, by saying ``I'm lost!''), the
behavior is then called \emph{transparent} \citep{kim_who_2006}, and the user
may hypothesize that the robot has \emph{introspective} capabilities (it can
reflect on its own internal state), which may lead to higher anthropomorphic
projections.  On the contrary, if the robot shows no sign of recognizing its own
failure, the user may ascribe a lower level of anthropomorphism to the robot.

In case II, the robot voluntary executes a behavior that is unexpected by the
human, and the human perceives it rightfully as an \emph{intentional} behavior.
For instance, the human asks the robot to go somewhere, and the robot refuses,
saying ``I do not want to go there''. In that case, we expect to see an increase
of attribution of anthropomorphism due to the human ascribing intentionality to
the robot.

Case IIIa and IIIb correspond to misinterpretations of the robot behavior. Case
IIIb may actually lead to an increased level of anthropomorphism since the human
will (wrongfully) attribute intentionality to the robot, while case IIIa is
expected to lead to a lower anthropomorphism level.  However, in those two
cases, the next occurrence of an expected behavior, if correctly interpreted
(case I or II), is likely to lead to stronger effects due to a larger $\delta$
between expectations and actual observed behavior. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				DISCUSSION + FUTURE WORK
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{sec:discussion}

The model of anthropomorphism we propose is still a work in progress. In
particular, its implications regarding the design of (social) robots and
human-robot interaction are still to be refined but we hope this article helps
encourage an open dialogue between those who do research of anthropomorphism.

Coming back to our two main hypotheses, on one hand we investigated how far
anthropomorphism is based on multiple factors, namely, the design of the robot,
the personal characteristics of the human user, and the context / situation in
which the robot is used.  We elaborated this hypothesis by reviewing literature
from various related disciplines. Based on the outcomes of this, on the other
hand, we proposed a model of the \emph{Dynamics of anthropomorphism}. We offered
a cognitive interpretation of this model, as well as illustrations from our own
previous work.  However, our model has limitations, for instance, regarding the
general effect of time and familiarization on anthropomorphism. We will discuss
this in the following section.


\subsection{Effect of time / familiarization on anthropomorphism}

We have proposed that time, or in other words, the user's familiarization with
the non-human agent, models how anthropomorphism evolves over time. Our general
assumption is that with continued interaction, and in turn growing user
experience, the system becomes more predictable and consequently, the user's
need to anthropomorphize the agent decreases. We would like to discuss this
suggestion here.

With \textit{time} as a factor, we referred to long-term interaction with the
robot, which is related to what has been described as \textit{novelty effect}
but also accounts for the user getting used to the robot. Several studies
described that after some time users interacted less with the robot or lost
interest in it. Sustaining long-term interaction is one of the main challenges
that robots with applications in daily life contexts face. Our question is that,
if we would like overcome the novelty effect, how far does the robot's
behavioral complexity play a role? Should the robot vary its behavior and behave
unexpectedly from time to time?

Most experiments, and even more when they investigate long-term interactions,
are carried out with robots exhibiting relatively simple behaviors. In our
model, the maximum level of anthropomorphism \AntMax is reached with the novelty
effect, and then decreases. A natural question is whether we can design robots
such that \AntMax remains high, possibly higher than $\ant[t_{novelty~peak}]$
(note that to know if sustaining strong anthropomorphic interaction is desirable
is entirely another question).

Intuitively, the behavioral complexity of the robot, and in particular, the
ability for the robot to evolve over time and \emph{adapt its behavior to the
user} as the user familiarizes his/herself with the robot (\ie
\emph{co-familiarize}), seems to play a key role.

Our model is based on the assumption that anthropomorphism tends to decrease
with the user becoming more familiar to the robot.  We explain this by the
general motivation to anthropomorphize an agent which might be difficult to
understand (in its functionality or behavior, for instance). In turn, a user
might ascribe intentions or emotions to the system because the system's output
was unexpected for the user, however he/she still wants to make sense of it.
Consequently, we estimate that when the user has familiarized herself/himself
with the system, thus reached the point of when the system is usable and
explainable, the tendency to anthropomorphize decreases. 

However, there exist views that suggest just the opposite, namely, that
familiarization and more interaction with an agent \textit{increase} the
tendency to anthropomorphize \citep{eddy_attribution_1993}. Similarly,
\cite{duffy_anthropomorphism_2003} reports that several psychological
experiments and human-robot interaction experiments showed that familiarity may
also ease social acceptance and even tend to \textit{increase} people's tendency
to anthropomorphize.

Consequently, we have to accept that our model of the \emph{Dynamics of
Anthropomorphism} needs to be verified, to see how far our hypotheses can hold.
In particular, the effect of the user's familiarity with the system needs to be
studied over a longer period of time.


\subsection{Measuring anthropomorphism}
\label{sec:measuring}

With this extended understanding of anthropomorphism being determined by
multiple factors and showing dynamics over time, it also becomes questionable if
the metrics and techniques that are currently used to measure anthropomorphism
are sufficient. We would like to discuss two issues: the scenario in which
anthropomorphism is measured, and how, with which means it is assessed.

One needs to keep in mind that anthropomorphism arises in an interaction. We
believe that as such, anthropomorphism can be better understood when studied and
measured in a real, direct human-robot interaction compared to a mediated
interaction. In a direct interaction scenario one could also take the human's
behavior into account, as it seems to reflect an anthropomorphic interaction
\citep{krach_can_2008,hegel_understanding_2008,weiss_i_2009}.  Of course, the
scenario and measurements one uses depend on the research questions, so a direct
human-robot interaction might not always be preferred.

However, most of the experiments that investigate anthropomorphism in HRI are
conducted in controlled lab-settings during a short-term scenario. For instance,
pictures or videos of different robots are shown to human subjects who
subsequently fill in a questionnaire, to assess how far the different types of
robots were perceived human-like.\footnote{It can already be critical to not
indicate the height / size of a robot when it is pictured or presented in a
video. We cannot assume that without any point of reference, lay people estimate
correctly the height of ASIMO or Nao, for instance, they might think these
humanoid robots are the same size as a Barbie doll. Also, when showing a
picture, the movements, behaviors, materials of a robot, and so forth are
totally disregarded. However, these aspects are also crucial features of a
robot, impacting how human-like it appears.} We think that such experimental
settings have limitations for studying a social phenomenon like
anthropomorphism. The critical question is: can anthropomorphism really be
measured in a post-interaction closed questionnaire or by rating scales?
Findings might possibly lead to interpretations that would not be generalizable
to natural settings or real interaction scenarios (which is always an issue in
social science research).

Regarding the second issue, how and with which means anthropomorphism is
measured, one of the view existing tools to do so is 5-item anthropomorphism
part of the Godspeed questionnaire \citep{bartneck_measurement_2008}. On 5 point
semantic differential scales, people are asked to rate the following constructs:
fake - natural, machinelike - humanlike, unconscious - conscious, artificial -
lifelike, moving rigidly - moving elegantly. The critical point that we see with
this is that ``human-likeness'' itself is complex and manifold. Being such an
abstract concept, instead of asking the vague question, whether a robot is
human-like or not, \cite{kahn_jr._robotic_2006} suggest to ask for more concrete
constructs that are typical or unique of the concept of ``human-likeness''.  For
instance, \cite{ruijten_introducing_2014} propose a 25-item questions to measure
various concrete aspects of human-likeness. Consequently, anthropomorphism can
be modeled along a scale that accounts for lower and higher levels of it.

Still, we also feel that measuring anthropomorphism (or social engagement with a
robot) is challenging because the phenomenon is partially unconscious, its
mediation is largely subject-dependent, and we found the phenomenon generally
difficult to verbalize for users.

To reduce subjectivity and still accurately account for psychological effects,
it appears necessary to interleave quantitative and qualitative assessments of
anthropomorphic effects.

We present in this section the methodology and techniques that we used to assess
anthropomorphic projections in the child-robot interaction study, called the
Domino study (see Section \ref{sec:field-results}, and Figure \ref{fig:ranger}).

\paragraph{Qualitative and quantitative assessment of anthropomorphism in
human's behavior\\}

Anthropomorphism can possibly be observed in how humans behave toward a
non-human agent (social human-like engagement). Based on video recordings of the
Domino experiment, we acquired both quantitative and qualitative behavioral data
that reflects anthropomorphism.

Quantitative data are acquired by systematic annotations of specific types of
actions in the video records of the interaction. Six classes of interactions
were identified as reflecting active commitment and/or an anthropomorphic
interaction of the user: gestures toward the robot, touching the robot, direct
talk to the robot, showing something to the robot, mistreating the robot (\eg
kicking it), and looking at the experimenter because worried by the robot's
behavior.

By considering the number of occurrences, the duration, and consequently the
frequency of these types of interaction, we can make statements of how far the
robot is anthropomorphized in an interaction (based on quantitative data).

We assessed anthropomorphic interactions qualitatively by looking at specific
instances of human-social cues in the human's behavior, such as: facial
expressions, observable emotional reactions (\eg surprised, high pitch voice or
shouting to the robot), eye-contact with the robot, turn-taking gestures,
greeting (waving) gestures. These are just suggestions of actions that might
reflect anthropomorphism. These actions partly overlap with the quantitative
assessment, however it is generally advisable to combine the two.


\paragraph{Qualitative assessment of anthropomorphism when verbally referring to
the robot (reflection)\\}

The main tools for qualitative measurement of anthropomorphic effect are
questionnaires and semi-structured interviews. We have explored both
rating-scales in a questionnaire, and open questions in an interview.  In the
Domino study, interviews were transcribed and participant's answers to the key
questions that were assessing an anthropomorphic projection onto the robot, were
analyzed. For instance, one question to see how far children would ascribe moral
standing to the robot was \emph{``If you had this robot at home, and you were to
leave for 2 weeks of holidays, would it be ok to leave the robot alone at
home?''}. A point for anthropomorphism was counted, when the participant's
answer indicated an anthropomorphic view of the robot. This process led to a
``qualitative score'' that reflects how far the robot is anthropomorphized. We
used the following constructs to measure how far the robot is perceived as a
human-like agent:

\begin{itemize}
    \item ~Spontaneously ascribe inner states, {\it eg. robot is
        hungry, tired}
    \item ~Ascribe ``own will'', {\it eg. robot could leave room by itself, does not
        always obey, could do a b\^{e}tise...}
    \item ~Describe robot as friend
    \item ~Ascribe cognitive abilities, {\it eg. robot is able to see,
        able to hear}
    \item ~Belief robot has feelings, {\it eg. robot can be happy or sad}
    \item ~Give anthropomorphic explanation for
        \begin{itemize}
            \item ~Why robot can (not) leave room alone {\it eg. it would be sad when left alone}
            \item ~Misbehavior {\it eg. robot wants to make a tour, doesn't
                like to play any longer}
        \end{itemize}
\end{itemize}

Some of these questions were taken from previous work done by
\cite{kahn_jr._robotic_2006} an \cite{weiss_i_2009}. In both studies, both
questionnaires and an analysis of behavior were used to assess children's and
adult's engagement with, and perception of the robot. This seems to be a
promising approach to investigate anthropomorphism, as it is also possible to
combine quantitative and qualitative techniques. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%				CONCLUSIONS
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\label{sec:conclusion}

Anthropomorphism is a social phenomenon which seems to be natural on one side
and very complex on the other side. It is a mechanism within oneself that makes
a human observer think and treat a non-human agent as if it would have some
human (social) characteristics, and ascribe to it intentions, emotions, or
thoughts, for instance. Understanding the reasons and modalities of
anthropomorphism is thus of prime importance to build a successful and lasting
human-robot interaction.

Based on our previous (and on-going) work, we hypothesized that there are
qualitative differences and dynamics over time in how humans relate to different
types of robots. More concretely, we described that people's perception of
human-likeness in a robot and in turn their human-social engagement with a robot
is based on four main factors: (1) the (anthropomorphic) design of the robot,
(2) individual characteristics of the human user, (3) the context of use /
interaction, and (4) the interaction history (time factor). We further suggested
that people's tendency to anthropomorphize a robot is likely to change over time
with growing experience of the user with the system. 

To formalize the variances in anthropomorphism, we proposed a model that we call
\textit{Dynamics of Anthropomorphism}.  

We introduced the concepts of \emph{initial capital} and \emph{stabilized level
of anthropomorphism} as compound factors to characterize the profile of a given
anthropomorphic (long-term) interaction.

The article also discussed the cognitive correlates of anthropomorphism. We
proposed three cognitive stages corresponding to successive refinements of the
mental models of the robot that the user builds during the interaction. We
showed how these stages relate to observable anthropomorphic effects, and how
they evolve over time.

While subject to discussion and further extensions, we hope that this
contribution consolidates the scientific grounds of anthropomorphism, and
provides support for a better understanding of long-term acceptance of robots in
human environments.


\section*{Acknowledgments}

This research was supported by the Swiss National Science Foundation through the
National Centre of Competence in Research Robotics.

\bibliographystyle{frontiersinSCNS&ENG} % for Science and Engineering articles
\bibliography{dynamics-anthropomorphism}   % name your BibTeX data base


\end{document}
